"""
Vertex AI ë™ì  ì›Œí¬ë¡œë“œ ìŠ¤ì¼€ì¤„ëŸ¬(DWS)ë¥¼ ì‚¬ìš©í•˜ì—¬ predict.pyë¥¼ ì‹¤í–‰í•˜ëŠ” ìŠ¤í¬ë¦½íŠ¸

ì´ ìŠ¤í¬ë¦½íŠ¸ëŠ” Vertex AI CustomJobì„ ì‚¬ìš©í•˜ì—¬ predict.pyë¥¼ ì‹¤í–‰í•©ë‹ˆë‹¤.
FLEX_START ìŠ¤ì¼€ì¤„ë§ ì „ëµì„ ì‚¬ìš©í•˜ì—¬ GPU ë¦¬ì†ŒìŠ¤ê°€ ì‚¬ìš© ê°€ëŠ¥í•´ì§ˆ ë•Œê¹Œì§€ ëŒ€ê¸°í•©ë‹ˆë‹¤.

ì‚¬ìš©ë²•:
    python run_predict_vertex_ai.py

í™˜ê²½ ë³€ìˆ˜:
    GCP_PROJECT_ID: Google Cloud í”„ë¡œì íŠ¸ ID
    GCP_REGION: ë¦¬ì „ (ì˜ˆ: us-central1)
    SUPABASE_URL: Supabase URL
    SUPABASE_KEY: Supabase Key
    GOOGLE_APPLICATION_CREDENTIALS: Google Cloud ì¸ì¦ ì •ë³´ íŒŒì¼ ê²½ë¡œ
"""

import os
import sys
from pathlib import Path
from typing import Optional
import logging
from dotenv import load_dotenv

# ë¡œê¹… ì„¤ì • (ë¨¼ì € ì´ˆê¸°í™”)
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

# .env íŒŒì¼ ë¡œë“œ (í”„ë¡œì íŠ¸ ë£¨íŠ¸ì—ì„œ)
env_file = Path(__file__).parent / ".env"
if env_file.exists():
    load_dotenv(env_file)
    logger.info(f".env íŒŒì¼ ë¡œë“œ ì™„ë£Œ: {env_file}")
else:
    # ìƒìœ„ ë””ë ‰í† ë¦¬ì—ì„œë„ ì‹œë„
    env_file = Path(__file__).parent.parent / ".env"
    if env_file.exists():
        load_dotenv(env_file)
        logger.info(f".env íŒŒì¼ ë¡œë“œ ì™„ë£Œ: {env_file}")
    else:
        logger.warning(f".env íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. í™˜ê²½ ë³€ìˆ˜ë¥¼ ì§ì ‘ ì„¤ì •í•˜ì„¸ìš”.")

# vertex-ai-key.json íŒŒì¼ ìë™ ì°¾ê¸° ë° ì„¤ì •
if not os.getenv("GOOGLE_APPLICATION_CREDENTIALS"):
    # ì—¬ëŸ¬ ê²½ë¡œì—ì„œ vertex-ai-key.json ì°¾ê¸°
    possible_paths = [
        Path(__file__).parent / "credentials" / "vertex-ai-key.json",
        Path(__file__).parent.parent / "credentials" / "vertex-ai-key.json",
        Path(__file__).parent / "vertex-ai-key.json",
    ]
    
    for creds_path in possible_paths:
        if creds_path.exists():
            abs_path = str(creds_path.resolve())
            os.environ["GOOGLE_APPLICATION_CREDENTIALS"] = abs_path
            logger.info(f"âœ… vertex-ai-key.json íŒŒì¼ ìë™ ì„¤ì •: {abs_path}")
            break
    else:
        logger.warning("âš ï¸ vertex-ai-key.json íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

# Vertex AI SDK
from google.cloud import aiplatform
from google.cloud.aiplatform_v1.types import custom_job as gca_custom_job_compat
from google.cloud import storage


def get_env_var(var_name: str, default: Optional[str] = None) -> str:
    """í™˜ê²½ ë³€ìˆ˜ë¥¼ ê°€ì ¸ì˜¤ê³  ì—†ìœ¼ë©´ ì—ëŸ¬ë¥¼ ë°œìƒì‹œí‚µë‹ˆë‹¤."""
    value = os.getenv(var_name, default)
    if value is None:
        raise ValueError(f"í™˜ê²½ ë³€ìˆ˜ {var_name}ì´ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
    return value


def check_authentication() -> bool:
    """
    Google Cloud ì¸ì¦ì´ ì œëŒ€ë¡œ ì„¤ì •ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸í•©ë‹ˆë‹¤.
    
    Returns:
        ì¸ì¦ì´ ì„¤ì •ë˜ì–´ ìˆìœ¼ë©´ True, ì•„ë‹ˆë©´ False
    """
    try:
        # í™˜ê²½ ë³€ìˆ˜ë¡œ ì¸ì¦ ì •ë³´ í™•ì¸
        creds_path = os.getenv("GOOGLE_APPLICATION_CREDENTIALS")
        if creds_path:
            if os.path.exists(creds_path):
                logger.info(f"âœ… ì„œë¹„ìŠ¤ ê³„ì • í‚¤ íŒŒì¼ ë°œê²¬: {creds_path}")
                return True
            else:
                logger.warning(f"âš ï¸ ì¸ì¦ íŒŒì¼ ê²½ë¡œê°€ ì„¤ì •ë˜ì—ˆì§€ë§Œ íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {creds_path}")
        
        # vertex-ai-key.json ìë™ ì°¾ê¸° ì‹œë„
        possible_paths = [
            Path(__file__).parent / "credentials" / "vertex-ai-key.json",
            Path(__file__).parent.parent / "credentials" / "vertex-ai-key.json",
            Path(__file__).parent / "vertex-ai-key.json",
        ]
        
        for creds_path in possible_paths:
            if creds_path.exists():
                abs_path = str(creds_path.resolve())
                os.environ["GOOGLE_APPLICATION_CREDENTIALS"] = abs_path
                logger.info(f"âœ… vertex-ai-key.json íŒŒì¼ ìë™ ë°œê²¬ ë° ì„¤ì •: {abs_path}")
                return True
        
        # gcloud CLI ì¸ì¦ í™•ì¸
        try:
            from google.auth import default
            credentials, project = default()
            logger.info(f"âœ… gcloud CLI ì¸ì¦ í™•ì¸ ì™„ë£Œ")
            return True
        except Exception as e:
            logger.warning(f"gcloud CLI ì¸ì¦ í™•ì¸ ì‹¤íŒ¨: {e}")
            return False
            
    except Exception as e:
        logger.warning(f"ì¸ì¦ í™•ì¸ ì¤‘ ì˜¤ë¥˜: {e}")
        return False


def ensure_bucket_exists(bucket_name: str, project: str, location: str) -> bool:
    """
    Cloud Storage ë²„í‚·ì´ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸í•˜ê³ , ì—†ìœ¼ë©´ ìƒì„±í•©ë‹ˆë‹¤.
    
    Args:
        bucket_name: ë²„í‚· ì´ë¦„
        project: Google Cloud í”„ë¡œì íŠ¸ ID
        location: ë¦¬ì „ (ì˜ˆ: us-central1)
    
    Returns:
        ë²„í‚·ì´ ì¡´ì¬í•˜ê±°ë‚˜ ìƒì„±ë˜ì—ˆìœ¼ë©´ True, ì‹¤íŒ¨í•˜ë©´ False
    """
    try:
        storage_client = storage.Client(project=project)
        
        # ë²„í‚· ì¡´ì¬ ì—¬ë¶€ í™•ì¸
        try:
            bucket = storage_client.bucket(bucket_name)
            if bucket.exists():
                logger.info(f"âœ… ë²„í‚·ì´ ì´ë¯¸ ì¡´ì¬í•©ë‹ˆë‹¤: {bucket_name}")
                return True
        except Exception as e:
            logger.warning(f"ë²„í‚· í™•ì¸ ì¤‘ ì˜¤ë¥˜: {e}")
        
        # ë²„í‚·ì´ ì—†ìœ¼ë©´ ìƒì„±
        logger.info(f"ë²„í‚·ì´ ì—†ìŠµë‹ˆë‹¤. ìƒì„± ì¤‘: {bucket_name}")
        bucket = storage_client.create_bucket(
            bucket_name,
            location=location
        )
        logger.info(f"âœ… ë²„í‚· ìƒì„± ì™„ë£Œ: {bucket_name}")
        return True
        
    except Exception as e:
        logger.error(f"âŒ ë²„í‚· ìƒì„± ì‹¤íŒ¨: {e}")
        logger.error("=" * 60)
        logger.error("ë²„í‚·ì„ ìˆ˜ë™ìœ¼ë¡œ ìƒì„±í•˜ë ¤ë©´ ë‹¤ìŒ ëª…ë ¹ì„ ì‹¤í–‰í•˜ì„¸ìš”:")
        logger.error(f"  gsutil mb -p {project} -l {location} gs://{bucket_name}")
        logger.error("=" * 60)
        return False


def create_custom_job_with_dws(
    project: str,
    location: str,
    staging_bucket: str,
    display_name: str,
    script_path: Optional[str] = None,  # ë¡œì»¬ íŒŒì¼ ê²½ë¡œ (deprecated: package_uri ì‚¬ìš© ê¶Œì¥)
    package_uri: Optional[str] = None,  # GCSì— ìˆëŠ” tar.gz íŒ¨í‚¤ì§€ URI (gs://bucket/package.tar.gz)
    python_module: str = "aiplatform_custom_trainer_script.task",  # ì‹¤í–‰í•  Python ëª¨ë“ˆ
    container_uri: Optional[str] = None,
    service_account: Optional[str] = None,
    machine_type: str = "n1-standard-4",
    accelerator_type: str = "NVIDIA_TESLA_T4",
    accelerator_count: int = 1,
    max_wait_duration: int = 1800,  # 30ë¶„ (ì´ˆ ë‹¨ìœ„)
    timeout: int = 3600,  # 1ì‹œê°„ (ì´ˆ ë‹¨ìœ„)
    environment_variables: Optional[dict] = None,
) -> str:
    """
    ë™ì  ì›Œí¬ë¡œë“œ ìŠ¤ì¼€ì¤„ëŸ¬(DWS)ë¥¼ ì‚¬ìš©í•˜ì—¬ CustomJobì„ ìƒì„±í•˜ê³  ì‹¤í–‰í•©ë‹ˆë‹¤.
    
    Args:
        project: Google Cloud í”„ë¡œì íŠ¸ ID
        location: ë¦¬ì „ (ì˜ˆ: us-central1)
        staging_bucket: Cloud Storage ë²„í‚· ì´ë¦„
        display_name: Job í‘œì‹œ ì´ë¦„
        script_path: ì‹¤í–‰í•  Python ìŠ¤í¬ë¦½íŠ¸ ê²½ë¡œ (ë¡œì»¬ íŒŒì¼, deprecated: package_uri ì‚¬ìš© ê¶Œì¥)
        package_uri: GCSì— ìˆëŠ” tar.gz íŒ¨í‚¤ì§€ URI (ì˜ˆ: gs://bucket/package.tar.gz)
        python_module: ì‹¤í–‰í•  Python ëª¨ë“ˆ (ê¸°ë³¸ê°’: aiplatform_custom_trainer_script.task)
        container_uri: ì»¤ìŠ¤í…€ ì»¨í…Œì´ë„ˆ ì´ë¯¸ì§€ URI (Noneì´ë©´ TensorFlow GPU ì»¨í…Œì´ë„ˆ ì‚¬ìš©)
        service_account: ì„œë¹„ìŠ¤ ê³„ì • ì´ë©”ì¼ (ì„ íƒì‚¬í•­)
        machine_type: ë¨¸ì‹  íƒ€ì… (ê¸°ë³¸ê°’: n1-standard-4)
        accelerator_type: GPU íƒ€ì… (ê¸°ë³¸ê°’: NVIDIA_TESLA_T4)
        accelerator_count: GPU ê°œìˆ˜ (ê¸°ë³¸ê°’: 1)
        max_wait_duration: ë¦¬ì†ŒìŠ¤ë¥¼ ê¸°ë‹¤ë¦´ ìˆ˜ ìˆëŠ” ìµœëŒ€ ì‹œê°„ (ì´ˆ, ê¸°ë³¸ê°’: 1800 = 30ë¶„)
        timeout: Job ì‹¤í–‰ ìµœëŒ€ ì‹œê°„ (ì´ˆ, ê¸°ë³¸ê°’: 3600 = 1ì‹œê°„)
        environment_variables: í™˜ê²½ ë³€ìˆ˜ ë”•ì…”ë„ˆë¦¬
    
    Returns:
        Job ì´ë¦„ (ë¦¬ì†ŒìŠ¤ ì´ë¦„)
    """
    logger.info("=" * 60)
    logger.info("Vertex AI CustomJob ìƒì„± ì‹œì‘ (DWS ì‚¬ìš©)")
    logger.info("=" * 60)
    
    # Vertex AI ì´ˆê¸°í™”
    aiplatform.init(
        project=project,
        location=location,
        staging_bucket=staging_bucket
    )
    
    logger.info(f"í”„ë¡œì íŠ¸: {project}")
    logger.info(f"ë¦¬ì „: {location}")
    logger.info(f"ìŠ¤í…Œì´ì§• ë²„í‚·: {staging_bucket}")
    logger.info(f"ë¨¸ì‹  íƒ€ì…: {machine_type}")
    logger.info(f"GPU íƒ€ì…: {accelerator_type}")
    logger.info(f"GPU ê°œìˆ˜: {accelerator_count}")
    logger.info(f"ìµœëŒ€ ëŒ€ê¸° ì‹œê°„: {max_wait_duration}ì´ˆ ({max_wait_duration/60:.1f}ë¶„)")
    logger.info(f"ìµœëŒ€ ì‹¤í–‰ ì‹œê°„: {timeout}ì´ˆ ({timeout/60:.1f}ë¶„)")
    
    # package_uri ë˜ëŠ” script_path í™•ì¸
    use_existing_package = package_uri is not None
    temp_script_path = None  # ì„ì‹œ íŒŒì¼ ê²½ë¡œ ì¶”ì ìš©
    
    if use_existing_package:
        # ì´ë¯¸ ìƒì„±ëœ íŒ¨í‚¤ì§€ ì‚¬ìš©
        if not package_uri.startswith("gs://"):
            raise ValueError(f"package_uriëŠ” GCS URI í˜•ì‹ì´ì–´ì•¼ í•©ë‹ˆë‹¤: {package_uri}")
        logger.info(f"ê¸°ì¡´ íŒ¨í‚¤ì§€ ì‚¬ìš©: {package_uri}")
        
        # íŒ¨í‚¤ì§€ ì¡´ì¬ í™•ì¸
        from google.cloud import storage as gcs_storage
        gcs_path_parts = package_uri.replace("gs://", "").split("/", 1)
        gcs_bucket_name = gcs_path_parts[0]
        gcs_blob_name = gcs_path_parts[1] if len(gcs_path_parts) > 1 else ""
        
        storage_client = gcs_storage.Client(project=project)
        bucket = storage_client.bucket(gcs_bucket_name)
        blob = bucket.blob(gcs_blob_name)
        
        if not blob.exists():
            raise FileNotFoundError(f"GCSì—ì„œ íŒ¨í‚¤ì§€ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {package_uri}")
        logger.info(f"íŒ¨í‚¤ì§€ íŒŒì¼ í™•ì¸ ì™„ë£Œ: {package_uri}")
        
    elif script_path:
        # ë¡œì»¬ ìŠ¤í¬ë¦½íŠ¸ ì‚¬ìš© (ê¸°ì¡´ ë°©ì‹)
        logger.info(f"ë¡œì»¬ ìŠ¤í¬ë¦½íŠ¸ ì‚¬ìš©: {script_path}")
        script_path_obj = Path(script_path)
        if not script_path_obj.exists():
            raise FileNotFoundError(f"ë¡œì»¬ ìŠ¤í¬ë¦½íŠ¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {script_path}")
        logger.info(f"ë¡œì»¬ ìŠ¤í¬ë¦½íŠ¸ íŒŒì¼ í™•ì¸ ì™„ë£Œ: {script_path}")
    else:
        raise ValueError("package_uri ë˜ëŠ” script_path ì¤‘ í•˜ë‚˜ëŠ” ë°˜ë“œì‹œ ì œê³µí•´ì•¼ í•©ë‹ˆë‹¤.")
    
    # í™˜ê²½ ë³€ìˆ˜ ì„¤ì •
    env_vars = environment_variables or {}
    
    # Supabase í™˜ê²½ ë³€ìˆ˜ ì¶”ê°€ (ì—†ìœ¼ë©´ ê¸°ë³¸ê°’ ì‚¬ìš©)
    if "SUPABASE_URL" not in env_vars:
        supabase_url = os.getenv("SUPABASE_URL")
        if supabase_url:
            env_vars["SUPABASE_URL"] = supabase_url
    
    if "SUPABASE_KEY" not in env_vars:
        supabase_key = os.getenv("SUPABASE_KEY")
        if supabase_key:
            env_vars["SUPABASE_KEY"] = supabase_key
    
    logger.info(f"í™˜ê²½ ë³€ìˆ˜ ê°œìˆ˜: {len(env_vars)}")
    if env_vars:
        logger.info(f"í™˜ê²½ ë³€ìˆ˜ í‚¤: {list(env_vars.keys())}")
    
        # CustomJob ìƒì„±
    try:
        # container_uri ì„¤ì •
        if not container_uri:
            container_uri = "us-docker.pkg.dev/vertex-ai/training/tf-gpu.2-11.py310:latest"
            logger.info(f"ì»¨í…Œì´ë„ˆ URIê°€ ì§€ì •ë˜ì§€ ì•Šì•„ ê¸°ë³¸ê°’ ì‚¬ìš©: {container_uri}")
        else:
            logger.info(f"ì»¤ìŠ¤í…€ ì»¨í…Œì´ë„ˆ ì‚¬ìš©: {container_uri}")
        
        # predict.pyì— í•„ìš”í•œ íŒ¨í‚¤ì§€ ëª©ë¡
        required_packages = [
            "supabase>=2.0.0",
            "pandas>=2.0.0",
            "numpy>=1.24.0",
            "scikit-learn>=1.3.0",
            "tensorflow>=2.11.0",
            "matplotlib>=3.7.0",
        ]
        
        if use_existing_package:
            # ì´ë¯¸ ìƒì„±ëœ íŒ¨í‚¤ì§€ ì‚¬ìš©
            logger.info("=" * 60)
            logger.info("CustomJob ìƒì„± (ê¸°ì¡´ íŒ¨í‚¤ì§€ ì‚¬ìš©)")
            logger.info("=" * 60)
            logger.info(f"  display_name: {display_name}")
            logger.info(f"  package_uri: {package_uri}")
            logger.info(f"  python_module: {python_module}")
            logger.info(f"  container_uri: {container_uri}")
            logger.info(f"  machine_type: {machine_type}")
            logger.info(f"  accelerator_type: {accelerator_type}")
            logger.info(f"  accelerator_count: {accelerator_count}")
            logger.info(f"  requirements: {required_packages}")
            logger.info(f"  environment_variables: {len(env_vars) if env_vars else 0}ê°œ")
            logger.info("=" * 60)
            
            # CustomJobì„ ì§ì ‘ êµ¬ì„±
            from google.cloud.aiplatform_v1.types import custom_job as gca_custom_job
            from google.cloud.aiplatform_v1.types import io as gca_io
            from google.cloud.aiplatform_v1.types import machine_resources
            
            # WorkerPoolSpec ìƒì„±
            # í™˜ê²½ ë³€ìˆ˜ë¥¼ WorkerPoolSpecì— ì¶”ê°€
            env_vars_list = []
            if env_vars:
                from google.cloud import aiplatform_v1
                for key, value in env_vars.items():
                    env_vars_list.append(
                        aiplatform_v1.types.EnvVar(name=key, value=str(value))
                    )
                logger.info(f"í™˜ê²½ ë³€ìˆ˜ {len(env_vars_list)}ê°œë¥¼ WorkerPoolSpecì— ì¶”ê°€í•©ë‹ˆë‹¤: {list(env_vars.keys())}")
            
            # PythonPackageSpec ìƒì„± (í™˜ê²½ ë³€ìˆ˜ í¬í•¨)
            python_package_spec = gca_custom_job.PythonPackageSpec(
                executor_image_uri=container_uri,
                package_uris=[package_uri],
                python_module=python_module,
            )
            
            # í™˜ê²½ ë³€ìˆ˜ê°€ ìˆìœ¼ë©´ PythonPackageSpecì— ì¶”ê°€
            if env_vars_list:
                python_package_spec.env = env_vars_list
            
            worker_pool_spec = gca_custom_job.WorkerPoolSpec(
                machine_spec=machine_resources.MachineSpec(
                    machine_type=machine_type,
                    accelerator_type=accelerator_type,
                    accelerator_count=accelerator_count,
                ),
                replica_count=1,
                python_package_spec=python_package_spec,
            )
            
            # CustomJob ìƒì„±
            # base_output_dirì€ ë¬¸ìì—´ë¡œ ì „ë‹¬ (GcsDestination ê°ì²´ê°€ ì•„ë‹Œ)
            base_output_uri = f"gs://{staging_bucket}"
            job = aiplatform.CustomJob(
                display_name=display_name,
                worker_pool_specs=[worker_pool_spec],
                base_output_dir=base_output_uri,
            )
            
            if env_vars:
                logger.info(f"âœ… í™˜ê²½ ë³€ìˆ˜ê°€ WorkerPoolSpecì— ì„¤ì •ë˜ì—ˆìŠµë‹ˆë‹¤: {list(env_vars.keys())}")
            
            logger.info("ê¸°ì¡´ íŒ¨í‚¤ì§€ë¥¼ ì‚¬ìš©í•œ CustomJob ê°ì²´ ìƒì„± ì™„ë£Œ")
        else:
            # ë¡œì»¬ ìŠ¤í¬ë¦½íŠ¸ ì‚¬ìš© (ê¸°ì¡´ ë°©ì‹)
            logger.info("=" * 60)
            logger.info("CustomJob ìƒì„± (ë¡œì»¬ ìŠ¤í¬ë¦½íŠ¸ ì‚¬ìš©)")
            logger.info("=" * 60)
            logger.info(f"  display_name: {display_name}")
            logger.info(f"  script_path: {script_path}")
            logger.info(f"  container_uri: {container_uri}")
            logger.info(f"  machine_type: {machine_type}")
            logger.info(f"  accelerator_type: {accelerator_type}")
            logger.info(f"  accelerator_count: {accelerator_count}")
            logger.info(f"  requirements: {required_packages}")
            logger.info(f"  environment_variables: {len(env_vars) if env_vars else 0}ê°œ")
            logger.info("=" * 60)
            
            job_kwargs = {
                "display_name": display_name,
                "script_path": script_path,
                "container_uri": container_uri,
                "machine_type": machine_type,
                "accelerator_type": accelerator_type,
                "accelerator_count": accelerator_count,
                "requirements": required_packages,
            }
            
            if env_vars:
                job_kwargs["environment_variables"] = env_vars
            
            logger.info(f"from_local_script í˜¸ì¶œ ì‹œì‘...")
            job = aiplatform.CustomJob.from_local_script(**job_kwargs)
            logger.info(f"from_local_script í˜¸ì¶œ ì™„ë£Œ")
        
        logger.info(f"from_local_script í˜¸ì¶œ ì™„ë£Œ")
        
        logger.info(f"CustomJob ê°ì²´ ìƒì„± ì™„ë£Œ: {display_name}")
        
        # DWS(FLEX_START) ì§€ì› ì—¬ë¶€ í™•ì¸
        # DWSëŠ” L4, A100, H100, H200, B200ë§Œ ì§€ì› (T4ëŠ” ì§€ì› ì•ˆ í•¨)
        # ë‹¨, FLEX_STARTëŠ” preemptible ì¸ìŠ¤í„´ìŠ¤ë¥¼ ì‚¬ìš©í•˜ë¯€ë¡œ í• ë‹¹ëŸ‰ì´ í•„ìš”í•¨
        flex_start_supported_gpus = [
            "NVIDIA_L4",
            "NVIDIA_TESLA_A100",
            "NVIDIA_A100_80GB",
            "NVIDIA_H100_80GB",
            "NVIDIA_H200",
            "NVIDIA_B200"
        ]
        
        # í™˜ê²½ ë³€ìˆ˜ë¡œ FLEX_START ì‚¬ìš© ì—¬ë¶€ ì œì–´ (ê¸°ë³¸ê°’: true)
        use_flex_start_env = os.getenv("VERTEX_AI_USE_FLEX_START", "true").lower()
        use_flex_start = (
            accelerator_type in flex_start_supported_gpus and 
            use_flex_start_env == "true"
        )
        
        if use_flex_start:
            logger.info("=" * 60)
            logger.info("CustomJob ì‹¤í–‰ ì‹œì‘ (FLEX_START ìŠ¤ì¼€ì¤„ë§ ì „ëµ)")
            logger.info("=" * 60)
            logger.info(f"GPU íƒ€ì… {accelerator_type}ì€ FLEX_STARTë¥¼ ì§€ì›í•©ë‹ˆë‹¤.")
            logger.info("GPU ë¦¬ì†ŒìŠ¤ê°€ ì‚¬ìš© ê°€ëŠ¥í•´ì§ˆ ë•Œê¹Œì§€ ëŒ€ê¸° ì¤‘...")
            
            job.run(
                service_account=service_account,
                max_wait_duration=max_wait_duration,
                timeout=timeout,
                scheduling_strategy=gca_custom_job_compat.Scheduling.Strategy.FLEX_START
            )
        else:
            logger.info("=" * 60)
            logger.info("CustomJob ì‹¤í–‰ ì‹œì‘ (ì¼ë°˜ ìŠ¤ì¼€ì¤„ë§)")
            logger.info("=" * 60)
            logger.warning(f"âš ï¸ GPU íƒ€ì… {accelerator_type}ì€ FLEX_STARTë¥¼ ì§€ì›í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
            logger.warning(f"ì¼ë°˜ ìŠ¤ì¼€ì¤„ë§ìœ¼ë¡œ ì‹¤í–‰ë©ë‹ˆë‹¤.")
            logger.info(f"FLEX_STARTë¥¼ ì‚¬ìš©í•˜ë ¤ë©´ ë‹¤ìŒ GPU ì¤‘ í•˜ë‚˜ë¥¼ ì‚¬ìš©í•˜ì„¸ìš”:")
            logger.info(f"  {', '.join(flex_start_supported_gpus)}")
            
            # ì¼ë°˜ ìŠ¤ì¼€ì¤„ë§ìœ¼ë¡œ ì‹¤í–‰ (FLEX_START ì—†ì´)
            job.run(
                service_account=service_account,
                timeout=timeout,
                # scheduling_strategyëŠ” ì§€ì •í•˜ì§€ ì•ŠìŒ (ê¸°ë³¸ ìŠ¤ì¼€ì¤„ë§ ì‚¬ìš©)
            )
        
        logger.info("=" * 60)
        logger.info("CustomJob ì‹¤í–‰ ì™„ë£Œ")
        logger.info("=" * 60)
        
        # ì„ì‹œ íŒŒì¼ ì •ë¦¬ (GCSì—ì„œ ë‹¤ìš´ë¡œë“œí•œ ê²½ìš°)
        if temp_script_path and os.path.exists(temp_script_path):
            try:
                os.remove(temp_script_path)
                logger.info(f"ì„ì‹œ íŒŒì¼ ì‚­ì œ ì™„ë£Œ: {temp_script_path}")
            except Exception as e:
                logger.warning(f"ì„ì‹œ íŒŒì¼ ì‚­ì œ ì‹¤íŒ¨ (ë¬´ì‹œ ê°€ëŠ¥): {e}")
        
        # run() í˜¸ì¶œ í›„ì— ë¦¬ì†ŒìŠ¤ ì •ë³´ ì ‘ê·¼ ê°€ëŠ¥
        try:
            logger.info(f"Job ìƒíƒœ: {job.state}")
            logger.info(f"Job ì´ë¦„: {job.name}")
            logger.info(f"Job ë¦¬ì†ŒìŠ¤ ì´ë¦„: {job.resource_name}")
            logger.info(f"Job ëŒ€ì‹œë³´ë“œ: https://console.cloud.google.com/vertex-ai/training/custom-jobs/{job.name}?project={project}")
        except Exception as e:
            logger.warning(f"Job ì •ë³´ ì¡°íšŒ ì¤‘ ì˜¤ë¥˜ (ë¬´ì‹œ ê°€ëŠ¥): {e}")
            logger.info(f"Job ëŒ€ì‹œë³´ë“œ: https://console.cloud.google.com/vertex-ai/training/custom-jobs?project={project}")
            
        return job.name if hasattr(job, 'name') else None
        
    except Exception as e:
        logger.error(f"CustomJob ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        import traceback
        traceback.print_exc()
        raise


def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    try:
        # .env íŒŒì¼ì—ì„œ í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ í™•ì¸
        logger.info("=" * 60)
        logger.info(".env íŒŒì¼ì—ì„œ í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ í™•ì¸")
        logger.info("=" * 60)
        
        # ì£¼ìš” í™˜ê²½ ë³€ìˆ˜ í™•ì¸ (ë””ë²„ê¹…ìš©)
        env_vars_to_check = [
            "GCP_PROJECT_ID", "GCP_REGION", "GCP_BUCKET_NAME", "GCP_STAGING_BUCKET",
            "SUPABASE_URL", "SUPABASE_KEY",
            "VERTEX_AI_GPU_TYPE", "VERTEX_AI_MACHINE_TYPE", "VERTEX_AI_GPU_COUNT",
            "GOOGLE_APPLICATION_CREDENTIALS"
        ]
        for var in env_vars_to_check:
            value = os.getenv(var)
            if value:
                # ë¯¼ê°í•œ ì •ë³´ëŠ” ì¼ë¶€ë§Œ í‘œì‹œ
                if "KEY" in var or "SECRET" in var:
                    logger.info(f"  {var}: {'*' * min(len(value), 20)}...")
                else:
                    logger.info(f"  {var}: {value}")
            else:
                logger.warning(f"  {var}: ì„¤ì •ë˜ì§€ ì•ŠìŒ (ê¸°ë³¸ê°’ ì‚¬ìš©)")
        
        logger.info("=" * 60)
        
        # Google Cloud ì¸ì¦ í™•ì¸
        logger.info("Google Cloud ì¸ì¦ í™•ì¸ ì¤‘...")
        if not check_authentication():
            logger.warning("âš ï¸ Google Cloud ì¸ì¦ì´ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            logger.warning("ë‹¤ìŒ ëª…ë ¹ì„ ì‹¤í–‰í•˜ì—¬ ì¸ì¦ì„ ì„¤ì •í•˜ì„¸ìš”:")
            logger.warning("  gcloud auth application-default login")
            logger.warning("ë˜ëŠ” .env íŒŒì¼ì— GOOGLE_APPLICATION_CREDENTIALSë¥¼ ì„¤ì •í•˜ì„¸ìš”.")
            logger.warning("ê³„ì† ì§„í–‰í•˜ì§€ë§Œ ì¸ì¦ ì˜¤ë¥˜ê°€ ë°œìƒí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤...")
        logger.info("=" * 60)
        
        # í™˜ê²½ ë³€ìˆ˜ì—ì„œ ì„¤ì • ê°€ì ¸ì˜¤ê¸°
        project = get_env_var("GCP_PROJECT_ID")
        location = get_env_var("GCP_REGION", "us-central1")
        
        # ìŠ¤í…Œì´ì§• ë²„í‚· (.env íŒŒì¼ì˜ GCP_BUCKET_NAME ë˜ëŠ” GCP_STAGING_BUCKET ì‚¬ìš©)
        staging_bucket = os.getenv("GCP_STAGING_BUCKET") or os.getenv("GCP_BUCKET_NAME")
        if not staging_bucket:
            # ë‘˜ ë‹¤ ì—†ìœ¼ë©´ ê¸°ë³¸ê°’ ì‚¬ìš©
            staging_bucket = f"{project}-vertex-ai-staging"
            logger.warning(f"GCP_STAGING_BUCKET ë˜ëŠ” GCP_BUCKET_NAMEì´ ì„¤ì •ë˜ì§€ ì•Šì•„ ê¸°ë³¸ê°’ ì‚¬ìš©: {staging_bucket}")
        else:
            logger.info(f"ë²„í‚· ì´ë¦„: {staging_bucket} (.envì—ì„œ ë¡œë“œë¨)")
        
        # ë²„í‚· ì´ë¦„ì—ì„œ 'gs://' ì ‘ë‘ì‚¬ ì œê±°
        if staging_bucket.startswith("gs://"):
            staging_bucket = staging_bucket[5:]
        
        # ë²„í‚·ì´ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸í•˜ê³  ì—†ìœ¼ë©´ ìƒì„±
        logger.info("=" * 60)
        logger.info("Cloud Storage ë²„í‚· í™•ì¸ ì¤‘...")
        logger.info("=" * 60)
        if not ensure_bucket_exists(staging_bucket, project, location):
            logger.error("ë²„í‚· ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. ìˆ˜ë™ìœ¼ë¡œ ìƒì„± í›„ ë‹¤ì‹œ ì‹œë„í•˜ì„¸ìš”.")
            sys.exit(1)
        
        # íŒ¨í‚¤ì§€ URI ë˜ëŠ” ìŠ¤í¬ë¦½íŠ¸ ê²½ë¡œ ì„¤ì •
        # 1ìˆœìœ„: VERTEX_AI_PACKAGE_URI (GCSì— ìˆëŠ” tar.gz íŒ¨í‚¤ì§€)
        # 2ìˆœìœ„: PREDICT_SCRIPT_PATH (ë¡œì»¬ íŒŒì¼)
        package_uri = os.getenv("VERTEX_AI_PACKAGE_URI")
        script_path = None
        
        if package_uri:
            logger.info(f"íŒ¨í‚¤ì§€ URI ì‚¬ìš©: {package_uri} (VERTEX_AI_PACKAGE_URI í™˜ê²½ ë³€ìˆ˜)")
        else:
            script_path = os.getenv("PREDICT_SCRIPT_PATH")
            if script_path:
                logger.info(f"ìŠ¤í¬ë¦½íŠ¸ ê²½ë¡œ ì‚¬ìš©: {script_path} (PREDICT_SCRIPT_PATH í™˜ê²½ ë³€ìˆ˜)")
            else:
                # ê¸°ë³¸ê°’: ê°€ì¥ ìµœì‹  ë²„ì „ì˜ íŒ¨í‚¤ì§€ ì‚¬ìš©
                package_uri = None
                logger.info("íŒ¨í‚¤ì§€ URIë‚˜ ìŠ¤í¬ë¦½íŠ¸ ê²½ë¡œê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
                logger.info("GCSì—ì„œ ê°€ì¥ ìµœì‹  ë²„ì „ì˜ íŒ¨í‚¤ì§€ë¥¼ ì°¾ëŠ” ì¤‘...")
                
                # GCSì—ì„œ ìµœì‹  ë²„ì „ íŒ¨í‚¤ì§€ ì°¾ê¸°
                from google.cloud import storage as gcs_storage
                import json
                import re
                
                storage_client = gcs_storage.Client(project=project)
                bucket = storage_client.bucket(staging_bucket)
                
                # ë°©ë²• 1: ë²„ì „ íŒŒì¼ì—ì„œ ìµœì‹  ë²„ì „ ì½ê¸°
                version_blob = bucket.blob("predict-package-version.json")
                if version_blob.exists():
                    try:
                        version_data = json.loads(version_blob.download_as_text())
                        latest_version = version_data.get("version", 0)
                        package_name = f"predict-package-v{latest_version}.tar.gz"
                        package_path = f"packages/{package_name}"
                        
                        # íŒ¨í‚¤ì§€ íŒŒì¼ ì¡´ì¬ í™•ì¸
                        package_blob = bucket.blob(package_path)
                        if package_blob.exists():
                            package_uri = f"gs://{staging_bucket}/{package_path}"
                            logger.info(f"âœ… ìµœì‹  ë²„ì „ íŒ¨í‚¤ì§€ ë°œê²¬: v{latest_version}")
                            logger.info(f"íŒ¨í‚¤ì§€ URI: {package_uri}")
                        else:
                            logger.warning(f"ë²„ì „ íŒŒì¼ì—ëŠ” v{latest_version}ì´ ìˆì§€ë§Œ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤. íŒ¨í„´ ê²€ìƒ‰ìœ¼ë¡œ ì°¾ëŠ” ì¤‘...")
                            package_uri = None  # ë°©ë²• 2ë¡œ í´ë°±
                    except Exception as e:
                        logger.warning(f"ë²„ì „ íŒŒì¼ ì½ê¸° ì‹¤íŒ¨: {e}")
                        package_uri = None  # ë°©ë²• 2ë¡œ í´ë°±
                
                # ë°©ë²• 2: íŒ¨í‚¤ì§€ íŒŒì¼ íŒ¨í„´ìœ¼ë¡œ ìµœëŒ€ ë²„ì „ ì°¾ê¸°
                if not package_uri:
                    blobs = list(bucket.list_blobs(prefix="packages/predict-package-v"))
                    version_pattern = re.compile(r'predict-package-v(\d+)\.tar\.gz')
                    
                    max_version = 0
                    latest_package_blob = None
                    
                    for blob in blobs:
                        match = version_pattern.search(blob.name)
                        if match:
                            version = int(match.group(1))
                            if version > max_version:
                                max_version = version
                                latest_package_blob = blob
                    
                    if latest_package_blob:
                        package_uri = f"gs://{staging_bucket}/{latest_package_blob.name}"
                        logger.info(f"âœ… ìµœì‹  ë²„ì „ íŒ¨í‚¤ì§€ ë°œê²¬: v{max_version}")
                        logger.info(f"íŒ¨í‚¤ì§€ URI: {package_uri}")
                    else:
                        # ë°©ë²• 3: ê¸°ì¡´ aiplatform-*.tar.gz íŒ¨í„´ (ë ˆê±°ì‹œ)
                        logger.warning("predict-package-v*.tar.gz íŒ¨í„´ì˜ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                        logger.warning("ë ˆê±°ì‹œ aiplatform-*.tar.gz íŒ¨í„´ì„ ê²€ìƒ‰ ì¤‘...")
                        
                        legacy_blobs = list(bucket.list_blobs(prefix="aiplatform-"))
                        if legacy_blobs:
                            legacy_blobs.sort(key=lambda x: x.time_created, reverse=True)
                            latest_package = legacy_blobs[0]
                            package_uri = f"gs://{staging_bucket}/{latest_package.name}"
                            logger.warning(f"ë ˆê±°ì‹œ íŒ¨í‚¤ì§€ ì‚¬ìš©: {package_uri}")
                        else:
                            raise ValueError(
                                "GCSì—ì„œ íŒ¨í‚¤ì§€ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. "
                                "ë‹¤ìŒ ì¤‘ í•˜ë‚˜ë¥¼ ìˆ˜í–‰í•˜ì„¸ìš”:\n"
                                "  1. VERTEX_AI_PACKAGE_URI í™˜ê²½ ë³€ìˆ˜ë¥¼ ì„¤ì •\n"
                                "  2. python upload_to_gcs.pyë¡œ íŒ¨í‚¤ì§€ ì—…ë¡œë“œ\n"
                                "  3. PREDICT_SCRIPT_PATHë¡œ ë¡œì»¬ ìŠ¤í¬ë¦½íŠ¸ ì‚¬ìš©"
                            )
        
        # Job ì„¤ì •
        display_name = get_env_var(
            "VERTEX_AI_JOB_NAME",
            "stock-prediction-dws-job"
        )
        
        # ë¨¸ì‹  ë° GPU ì„¤ì • (.env íŒŒì¼ì˜ ê°’ ìš°ì„  ì‚¬ìš©)
        # GPU íƒ€ì…ë³„ ë¨¸ì‹  íƒ€ì… ë§¤í•‘
        gpu_machine_mapping = {
            "NVIDIA_TESLA_T4": "n1-standard-4",
            "NVIDIA_L4": "g2-standard-4",
            "NVIDIA_TESLA_A100": "a2-highgpu-1g",
            "NVIDIA_A100_80GB": "a2-highgpu-1g",
            "NVIDIA_H100_80GB": "a3-highgpu-1g",
            "NVIDIA_H200": "a3-highgpu-1g",
            "NVIDIA_B200": "a3-highgpu-1g",
        }
        
        accelerator_type = os.getenv("VERTEX_AI_GPU_TYPE", "NVIDIA_TESLA_T4")
        accelerator_count = int(os.getenv("VERTEX_AI_GPU_COUNT", "1"))
        
        # ë¨¸ì‹  íƒ€ì…ì´ ëª…ì‹œì ìœ¼ë¡œ ì„¤ì •ë˜ì§€ ì•Šì•˜ìœ¼ë©´ GPU íƒ€ì…ì— ë§ëŠ” ê¸°ë³¸ê°’ ì‚¬ìš©
        machine_type = os.getenv("VERTEX_AI_MACHINE_TYPE")
        if not machine_type and accelerator_type in gpu_machine_mapping:
            machine_type = gpu_machine_mapping[accelerator_type]
            logger.info(f"ë¨¸ì‹  íƒ€ì…ì´ ì„¤ì •ë˜ì§€ ì•Šì•„ GPU íƒ€ì…ì— ë§ëŠ” ê¸°ë³¸ê°’ ì‚¬ìš©: {machine_type}")
        elif not machine_type:
            machine_type = "n1-standard-4"  # ê¸°ë³¸ê°’
            logger.warning(f"GPU íƒ€ì… {accelerator_type}ì— ëŒ€í•œ ê¸°ë³¸ ë¨¸ì‹  íƒ€ì…ì´ ì—†ì–´ ê¸°ë³¸ê°’ ì‚¬ìš©: {machine_type}")
        
        logger.info(f"ë¨¸ì‹  íƒ€ì…: {machine_type} (.envì—ì„œ ë¡œë“œë¨)")
        logger.info(f"GPU íƒ€ì…: {accelerator_type} (.envì—ì„œ ë¡œë“œë¨)")
        logger.info(f"GPU ê°œìˆ˜: {accelerator_count} (.envì—ì„œ ë¡œë“œë¨)")
        
        # ëŒ€ê¸° ì‹œê°„ ì„¤ì • (ì´ˆ ë‹¨ìœ„)
        # ê¸°ë³¸ê°’: 1800ì´ˆ (30ë¶„), 0ì´ë©´ ë¬´ì œí•œ ëŒ€ê¸°
        max_wait_duration = int(get_env_var(
            "VERTEX_AI_MAX_WAIT_DURATION",
            "1800"
        ))
        
        # íƒ€ì„ì•„ì›ƒ ì„¤ì • (ì´ˆ ë‹¨ìœ„, ìµœëŒ€ 7ì¼ = 604800ì´ˆ)
        timeout = int(get_env_var(
            "VERTEX_AI_TIMEOUT",
            "3600"  # 1ì‹œê°„
        ))
        
        # ì„œë¹„ìŠ¤ ê³„ì • (ì„ íƒì‚¬í•­)
        service_account = os.getenv("VERTEX_AI_SERVICE_ACCOUNT")
        
        # ì»¤ìŠ¤í…€ ì»¨í…Œì´ë„ˆ URI
        # .envì— ì„¤ì •ë˜ì–´ ìˆìœ¼ë©´ ì‚¬ìš©, ì—†ìœ¼ë©´ ê¸°ë³¸ê°’ ì‚¬ìš©
        container_uri = os.getenv("VERTEX_AI_CONTAINER_URI")
        if container_uri:
            logger.info(f"ì»¨í…Œì´ë„ˆ URI: {container_uri} (.envì—ì„œ ë¡œë“œë¨)")
        else:
            logger.info("ì»¨í…Œì´ë„ˆ URI: .envì— ì„¤ì •ë˜ì§€ ì•ŠìŒ (ê¸°ë³¸ê°’ ì‚¬ìš© ì˜ˆì •)")
        
        # í™˜ê²½ ë³€ìˆ˜ ë”•ì…”ë„ˆë¦¬
        environment_variables = {}
        
        # Supabase í™˜ê²½ ë³€ìˆ˜ ì¶”ê°€
        if os.getenv("SUPABASE_URL"):
            environment_variables["SUPABASE_URL"] = os.getenv("SUPABASE_URL")
        if os.getenv("SUPABASE_KEY"):
            environment_variables["SUPABASE_KEY"] = os.getenv("SUPABASE_KEY")
        
        # Python ëª¨ë“ˆ ê²½ë¡œ (ê¸°ë³¸ê°’)
        python_module = os.getenv("VERTEX_AI_PYTHON_MODULE", "aiplatform_custom_trainer_script.task")
        
        # CustomJob ìƒì„± ë° ì‹¤í–‰
        create_custom_job_with_dws(
            project=project,
            location=location,
            staging_bucket=staging_bucket,
            display_name=display_name,
            script_path=script_path,
            package_uri=package_uri,
            python_module=python_module,
            container_uri=container_uri,
            service_account=service_account,
            machine_type=machine_type,
            accelerator_type=accelerator_type,
            accelerator_count=accelerator_count,
            max_wait_duration=max_wait_duration,
            timeout=timeout,
            environment_variables=environment_variables if environment_variables else None,
        )
        
        logger.info("âœ… Job ì‹¤í–‰ì´ ì„±ê³µì ìœ¼ë¡œ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
        
    except Exception as e:
        error_msg = str(e)
        logger.error(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {error_msg}")
        
        # ì¸ì¦ ì˜¤ë¥˜ì¸ ê²½ìš° íŠ¹ë³„ ì•ˆë‚´
        if "authentication" in error_msg.lower() or "credentials" in error_msg.lower() or "auth" in error_msg.lower():
            logger.error("=" * 60)
            logger.error("ğŸ” Google Cloud ì¸ì¦ ì˜¤ë¥˜")
            logger.error("=" * 60)
            logger.error("ë‹¤ìŒ ì¤‘ í•˜ë‚˜ì˜ ë°©ë²•ìœ¼ë¡œ ì¸ì¦ì„ ì„¤ì •í•˜ì„¸ìš”:")
            logger.error("")
            logger.error("ë°©ë²• 1: gcloud CLI ì‚¬ìš© (ê¶Œì¥)")
            logger.error("  gcloud auth application-default login")
            logger.error("")
            logger.error("ë°©ë²• 2: ì„œë¹„ìŠ¤ ê³„ì • í‚¤ íŒŒì¼ ì‚¬ìš©")
            logger.error("  .env íŒŒì¼ì— ë‹¤ìŒì„ ì¶”ê°€:")
            logger.error("  GOOGLE_APPLICATION_CREDENTIALS=path/to/credentials.json")
            logger.error("")
            logger.error("ë°©ë²• 3: í™˜ê²½ ë³€ìˆ˜ë¡œ ì§ì ‘ ì„¤ì •")
            logger.error("  export GOOGLE_APPLICATION_CREDENTIALS='path/to/credentials.json'")
            logger.error("=" * 60)
        
        # ë²„í‚· ì˜¤ë¥˜ì¸ ê²½ìš°
        if "bucket" in error_msg.lower() or "404" in error_msg:
            logger.error("=" * 60)
            logger.error("ğŸ“¦ Cloud Storage ë²„í‚· ì˜¤ë¥˜")
            logger.error("=" * 60)
            logger.error("ë²„í‚·ì´ ì¡´ì¬í•˜ì§€ ì•Šê±°ë‚˜ ì ‘ê·¼í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            logger.error("ë²„í‚·ì„ ìˆ˜ë™ìœ¼ë¡œ ìƒì„±í•˜ë ¤ë©´:")
            project = os.getenv("GCP_PROJECT_ID", "your-project-id")
            location = os.getenv("GCP_REGION", "us-central1")
            staging_bucket = os.getenv("GCP_STAGING_BUCKET", f"{project}-vertex-ai-staging")
            if staging_bucket.startswith("gs://"):
                staging_bucket = staging_bucket[5:]
            logger.error(f"  gsutil mb -p {project} -l {location} gs://{staging_bucket}")
            logger.error("=" * 60)
        
        # ì»¨í…Œì´ë„ˆ ì´ë¯¸ì§€ ì˜¤ë¥˜ì¸ ê²½ìš°
        if "image" in error_msg.lower() and "not supported" in error_msg.lower():
            logger.error("=" * 60)
            logger.error("ğŸ³ ì»¨í…Œì´ë„ˆ ì´ë¯¸ì§€ ì˜¤ë¥˜")
            logger.error("=" * 60)
            logger.error("ì§€ì›ë˜ì§€ ì•ŠëŠ” ì»¨í…Œì´ë„ˆ ì´ë¯¸ì§€ì…ë‹ˆë‹¤.")
            logger.error("í•´ê²° ë°©ë²•:")
            logger.error("  .env íŒŒì¼ì— ì˜¬ë°”ë¥¸ Vertex AI Python íŒ¨í‚¤ì§€ í•™ìŠµìš© ì´ë¯¸ì§€ë¥¼ ì„¤ì •í•˜ì„¸ìš”:")
            logger.error("  VERTEX_AI_CONTAINER_URI=us-docker.pkg.dev/vertex-ai/training/tf-gpu.2-11.py310:latest")
            logger.error("  ë˜ëŠ” ë‹¤ë¥¸ ë²„ì „:")
            logger.error("  VERTEX_AI_CONTAINER_URI=us-docker.pkg.dev/vertex-ai/training/tf-gpu.2-13.py310:latest")
            logger.error("=" * 60)
        
        # container_uri í•„ìˆ˜ ì¸ì ì˜¤ë¥˜ì¸ ê²½ìš°
        if "missing 1 required positional argument: 'container_uri'" in error_msg:
            logger.error("=" * 60)
            logger.error("ğŸ³ container_uri í•„ìˆ˜ ì¸ì ì˜¤ë¥˜")
            logger.error("=" * 60)
            logger.error("SDK ë²„ì „ì— ë”°ë¼ container_uriê°€ í•„ìˆ˜ì…ë‹ˆë‹¤.")
            logger.error("í˜„ì¬ container_uri ê°’:")
            container_uri_debug = os.getenv("VERTEX_AI_CONTAINER_URI", "None (ì„¤ì •ë˜ì§€ ì•ŠìŒ)")
            logger.error(f"  VERTEX_AI_CONTAINER_URI: {container_uri_debug}")
            logger.error("í•´ê²° ë°©ë²•:")
            logger.error("  .env íŒŒì¼ì— ë‹¤ìŒì„ ì¶”ê°€í•˜ì„¸ìš”:")
            logger.error("  VERTEX_AI_CONTAINER_URI=us-docker.pkg.dev/vertex-ai/training/tf-gpu.2-11.py310:latest")
            logger.error("=" * 60)
        
        # FLEX_START ì§€ì› ì•ˆ ë˜ëŠ” GPU ì˜¤ë¥˜ì¸ ê²½ìš°
        if "flex_start" in error_msg.lower() and "not supported" in error_msg.lower():
            logger.error("=" * 60)
            logger.error("âš ï¸ FLEX_START ìŠ¤ì¼€ì¤„ë§ ì§€ì› ì˜¤ë¥˜")
            logger.error("=" * 60)
            logger.error("í˜„ì¬ GPU íƒ€ì…ì€ FLEX_START ìŠ¤ì¼€ì¤„ë§ì„ ì§€ì›í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
            current_gpu = os.getenv("VERTEX_AI_GPU_TYPE", "NVIDIA_TESLA_T4")
            logger.error(f"í˜„ì¬ GPU: {current_gpu}")
            logger.error("")
            logger.error("í•´ê²° ë°©ë²•:")
            logger.error("  1. ì¼ë°˜ ìŠ¤ì¼€ì¤„ë§ ì‚¬ìš© (ìë™ìœ¼ë¡œ ì²˜ë¦¬ë¨)")
            logger.error("     - T4ë¥¼ ì‚¬ìš©í•˜ë©´ ìë™ìœ¼ë¡œ ì¼ë°˜ ìŠ¤ì¼€ì¤„ë§ìœ¼ë¡œ ì‹¤í–‰ë©ë‹ˆë‹¤")
            logger.error("")
            logger.error("  2. FLEX_STARTë¥¼ ì‚¬ìš©í•˜ë ¤ë©´ ì§€ì›ë˜ëŠ” GPUë¡œ ë³€ê²½:")
            logger.error("     .env íŒŒì¼ì—ì„œ:")
            logger.error("     VERTEX_AI_GPU_TYPE=NVIDIA_L4")
            logger.error("     ë˜ëŠ”")
            logger.error("     VERTEX_AI_GPU_TYPE=NVIDIA_TESLA_A100")
            logger.error("")
            logger.error("ì§€ì›ë˜ëŠ” GPU: L4, A100, H100, H200, B200")
            logger.error("=" * 60)
        
        # GPU í• ë‹¹ëŸ‰ ì´ˆê³¼ ì˜¤ë¥˜ì¸ ê²½ìš°
        if "quota" in error_msg.lower() and "exceed" in error_msg.lower():
            logger.error("=" * 60)
            logger.error("âš ï¸ GPU í• ë‹¹ëŸ‰ ì´ˆê³¼ ì˜¤ë¥˜")
            logger.error("=" * 60)
            current_gpu = os.getenv("VERTEX_AI_GPU_TYPE", "NVIDIA_TESLA_T4")
            project = os.getenv("GCP_PROJECT_ID", "your-project-id")
            location = os.getenv("GCP_REGION", "us-central1")
            logger.error(f"í˜„ì¬ GPU: {current_gpu}")
            logger.error(f"í”„ë¡œì íŠ¸: {project}")
            logger.error(f"ë¦¬ì „: {location}")
            logger.error("")
            
            # preemptible í• ë‹¹ëŸ‰ ì˜¤ë¥˜ì¸ì§€ í™•ì¸
            is_preemptible_error = "preemptible" in error_msg.lower()
            if is_preemptible_error:
                logger.error("ğŸ“Œ FLEX_STARTëŠ” preemptible (ì„ ì í˜•) ì¸ìŠ¤í„´ìŠ¤ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.")
                logger.error("   preemptible í• ë‹¹ëŸ‰ì´ ë¶€ì¡±í•œ ê²½ìš° ì¼ë°˜ ìŠ¤ì¼€ì¤„ë§ì„ ì‚¬ìš©í•˜ì„¸ìš”.")
                logger.error("")
                logger.error("ğŸ’¡ ì¦‰ì‹œ í•´ê²° ë°©ë²•: FLEX_START ë¹„í™œì„±í™”")
                logger.error("   .env íŒŒì¼ì— ë‹¤ìŒì„ ì¶”ê°€:")
                logger.error("   VERTEX_AI_USE_FLEX_START=false")
                logger.error("   ì´ë ‡ê²Œ í•˜ë©´ ì¼ë°˜(non-preemptible) ì¸ìŠ¤í„´ìŠ¤ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.")
                logger.error("")
            
            logger.error("ğŸ“Œ ì¤‘ìš”: Colabê³¼ Vertex AIëŠ” í• ë‹¹ëŸ‰ ì‹œìŠ¤í…œì´ ë‹¤ë¦…ë‹ˆë‹¤!")
            logger.error("  - Colab: Colab ì „ìš© í• ë‹¹ëŸ‰ ì‚¬ìš© (ë¬´ë£Œ/í”„ë¦¬ë¯¸ì—„ ê³„ì • ê¸°ë°˜)")
            logger.error("  - Vertex AI: í”„ë¡œì íŠ¸ë³„ Vertex AI í• ë‹¹ëŸ‰ í•„ìš” (ë³„ë„ ìš”ì²­ í•„ìš”)")
            logger.error("")
            logger.error("Colabì—ì„œ T4 GPUê°€ ì‘ë™í–ˆì–´ë„, Vertex AIì—ì„œëŠ” í• ë‹¹ëŸ‰ì„ ë³„ë„ë¡œ ìš”ì²­í•´ì•¼ í•©ë‹ˆë‹¤.")
            logger.error("")
            logger.error("í•´ê²° ë°©ë²•:")
            logger.error("")
            logger.error("ë°©ë²• 1: FLEX_START ë¹„í™œì„±í™” (ì¦‰ì‹œ í•´ê²°, ê¶Œì¥)")
            logger.error("  .env íŒŒì¼ì— ì¶”ê°€:")
            logger.error("    VERTEX_AI_USE_FLEX_START=false")
            logger.error("  ì¼ë°˜(non-preemptible) ì¸ìŠ¤í„´ìŠ¤ë¥¼ ì‚¬ìš©í•˜ë¯€ë¡œ í• ë‹¹ëŸ‰ì´ ë” ë§ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
            logger.error("")
            logger.error("ë°©ë²• 2: í• ë‹¹ëŸ‰ ì¦ê°€ ìš”ì²­ (24-48ì‹œê°„ ì†Œìš”)")
            logger.error("  1. Google Cloud Console ì ‘ì†:")
            logger.error(f"     https://console.cloud.google.com/iam-admin/quotas?project={project}")
            if is_preemptible_error:
                logger.error("  2. ê²€ìƒ‰ì°½ì— 'preemptible_nvidia_l4' ë˜ëŠ” 'custom_model_training_preemptible_nvidia_l4_gpus' ì…ë ¥")
            else:
                logger.error("  2. ê²€ìƒ‰ì°½ì— 'nvidia_t4' ë˜ëŠ” 'custom_model_training_nvidia_t4_gpus' ì…ë ¥")
            logger.error(f"  3. ë¦¬ì „: {location} í•„í„° ì ìš©")
            logger.error("  4. í• ë‹¹ëŸ‰ í•­ëª© ì„ íƒ â†’ 'EDIT QUOTAS' í´ë¦­")
            logger.error("  5. ì›í•˜ëŠ” í• ë‹¹ëŸ‰ ì…ë ¥ (ì˜ˆ: 0 â†’ 1 ë˜ëŠ” 2)")
            logger.error("  6. ìš”ì²­ ì‚¬ìœ  ì‘ì„±:")
            logger.error("     'ì£¼ì‹ ì˜ˆì¸¡ ëª¨ë¸ í•™ìŠµì„ ìœ„í•œ Vertex AI Custom Job ì‹¤í–‰ì— í•„ìš”í•©ë‹ˆë‹¤.")
            logger.error("      í•˜ë£¨ 1íšŒ, ì•½ 30ë¶„~1ì‹œê°„ì”© ì‹¤í–‰ë˜ë©° ì›” ì‚¬ìš©ëŸ‰ì€ ì•½ 15ì‹œê°„ì…ë‹ˆë‹¤.'")
            logger.error("  7. 'Submit Request' í´ë¦­")
            logger.error("  8. ìŠ¹ì¸ ëŒ€ê¸° (ë³´í†µ 24-48ì‹œê°„, ê¸´ê¸‰ ì‹œ ì§€ì›íŒ€ ë¬¸ì˜)")
            logger.error("")
            logger.error("ë°©ë²• 3: ë‹¤ë¥¸ ë¦¬ì „ ì‚¬ìš©")
            logger.error("  .env íŒŒì¼ì—ì„œ:")
            logger.error("    GCP_REGION=us-east1  # ë‹¤ë¥¸ ë¦¬ì „ ì‹œë„ (í• ë‹¹ëŸ‰ì´ ë” ë§ì„ ìˆ˜ ìˆìŒ)")
            logger.error("")
            logger.error("ë°©ë²• 4: Colab Enterprise ì‚¬ìš© (Colabê³¼ ìœ ì‚¬í•œ í™˜ê²½)")
            logger.error("  Colab Enterpriseë¥¼ ì‚¬ìš©í•˜ë©´ Colabê³¼ ë™ì¼í•œ í• ë‹¹ëŸ‰ ì‹œìŠ¤í…œì„ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
            logger.error("  ìì„¸í•œ ë‚´ìš©ì€ Colab_Enterprise_ìŠ¤ì¼€ì¤„ë§_ê°€ì´ë“œ.md íŒŒì¼ì„ ì°¸ê³ í•˜ì„¸ìš”.")
            logger.error("")
            logger.error("ğŸ’¡ ì¶”ì²œ: ë°©ë²• 1 (FLEX_START ë¹„í™œì„±í™”) - ì¦‰ì‹œ í•´ê²° ê°€ëŠ¥í•©ë‹ˆë‹¤!")
            logger.error("")
            logger.error("ìì„¸í•œ ë‚´ìš©ì€ GPU_í• ë‹¹ëŸ‰_ì¦ê°€_ê°€ì´ë“œ.md íŒŒì¼ì„ ì°¸ê³ í•˜ì„¸ìš”.")
            logger.error("=" * 60)
        
        import traceback
        traceback.print_exc()
        sys.exit(1)


if __name__ == "__main__":
    main()
