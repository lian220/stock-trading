"""
predict.py íŒŒì¼ì„ GCS ë²„í‚·ì— ì—…ë¡œë“œí•˜ëŠ” ìŠ¤í¬ë¦½íŠ¸

ì‚¬ìš©ë²•:
    python upload_to_gcs.py [--file predict.py] [--bucket stock-trading-packages] [--path packages/predict.py]

í™˜ê²½ ë³€ìˆ˜:
    GCP_PROJECT_ID: Google Cloud í”„ë¡œì íŠ¸ ID
    GCP_BUCKET_NAME: Cloud Storage ë²„í‚· ì´ë¦„ (ê¸°ë³¸ê°’: stock-trading-packages)
    GOOGLE_APPLICATION_CREDENTIALS: Google Cloud ì¸ì¦ ì •ë³´ íŒŒì¼ ê²½ë¡œ
"""

import os
import sys
import argparse
from pathlib import Path
from typing import Optional
import logging
from dotenv import load_dotenv

# ë¡œê¹… ì„¤ì •
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

# .env íŒŒì¼ ë¡œë“œ (ì—†ì–´ë„ ê´œì°®ìŒ - í™˜ê²½ ë³€ìˆ˜ë‚˜ ë‹¤ë¥¸ ë°©ë²•ìœ¼ë¡œ ì„¤ì • ê°€ëŠ¥)
env_file = Path(__file__).parent / ".env"
if env_file.exists():
    load_dotenv(env_file)
    logger.debug(f".env íŒŒì¼ ë¡œë“œ ì™„ë£Œ: {env_file}")
# .env íŒŒì¼ì´ ì—†ì–´ë„ í™˜ê²½ ë³€ìˆ˜ë¡œ ì§ì ‘ ì„¤ì • ê°€ëŠ¥í•˜ë¯€ë¡œ ê²½ê³ ë¥¼ ì¶œë ¥í•˜ì§€ ì•ŠìŒ

# vertex-ai-key.json íŒŒì¼ ìë™ ì°¾ê¸° ë° ì„¤ì •
# ì£¼ì˜: ëª¨ë“ˆ ë¡œë“œ ì‹œì ì— ì‹¤í–‰ë˜ë¯€ë¡œ Docker í™˜ê²½ì—ì„œëŠ” í™˜ê²½ ë³€ìˆ˜ ì‚¬ìš© ê¶Œì¥
def setup_credentials():
    """ì¸ì¦ íŒŒì¼ì„ ì°¾ì•„ì„œ ì„¤ì •í•©ë‹ˆë‹¤. (í•„ìš”í•  ë•Œë§Œ í˜¸ì¶œ)"""
    if os.getenv("GOOGLE_APPLICATION_CREDENTIALS"):
        return  # ì´ë¯¸ ì„¤ì •ë¨
    
    # Docker í™˜ê²½ ì²´í¬ (ë¡œì»¬ ê²½ë¡œê°€ ì•„ë‹Œ ê²½ìš°)
    if Path("/app").exists() or Path("/").exists() and not Path("/Users").exists():
        # Docker ì»¨í…Œì´ë„ˆ ë‚´ë¶€ì—ì„œëŠ” í™˜ê²½ ë³€ìˆ˜ë‚˜ gcloud ì¸ì¦ ì‚¬ìš©
        logger.debug("Docker í™˜ê²½ ê°ì§€: í™˜ê²½ ë³€ìˆ˜ë‚˜ gcloud ì¸ì¦ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.")
        return
    
    # ë¡œì»¬ ê°œë°œ í™˜ê²½ì—ì„œë§Œ íŒŒì¼ ì°¾ê¸°
    possible_paths = [
        Path(__file__).parent / "credentials" / "vertex-ai-key.json",
        Path(__file__).parent.parent / "credentials" / "vertex-ai-key.json",
        Path(__file__).parent / "vertex-ai-key.json",
    ]
    
    for creds_path in possible_paths:
        if creds_path.exists():
            abs_path = str(creds_path.resolve())
            os.environ["GOOGLE_APPLICATION_CREDENTIALS"] = abs_path
            logger.info(f"âœ… vertex-ai-key.json íŒŒì¼ ìë™ ì„¤ì •: {abs_path}")
            return
    
    logger.debug("ë¡œì»¬ ì¸ì¦ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. í™˜ê²½ ë³€ìˆ˜ë‚˜ gcloud ì¸ì¦ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.")

# ëª¨ë“ˆ ë¡œë“œ ì‹œì ì—ëŠ” ì‹¤í–‰í•˜ì§€ ì•ŠìŒ (í•¨ìˆ˜ í˜¸ì¶œ ì‹œì ì—ë§Œ ì‹¤í–‰)

from google.cloud import storage
import json
import re
import tarfile
import tempfile
import shutil
from datetime import datetime


def upload_file_to_gcs(
    bucket_name: str,
    source_file: str,
    destination_blob_name: str,
    project: Optional[str] = None
) -> str:
    """
    ë¡œì»¬ íŒŒì¼ì„ GCS ë²„í‚·ì— ì—…ë¡œë“œí•©ë‹ˆë‹¤.
    
    Args:
        bucket_name: GCS ë²„í‚· ì´ë¦„ (gs:// ì œì™¸)
        source_file: ì—…ë¡œë“œí•  ë¡œì»¬ íŒŒì¼ ê²½ë¡œ
        destination_blob_name: GCS ë‚´ ëª©ì ì§€ ê²½ë¡œ (ì˜ˆ: packages/predict.py)
        project: Google Cloud í”„ë¡œì íŠ¸ ID (ì„ íƒì‚¬í•­)
    
    Returns:
        ì—…ë¡œë“œëœ íŒŒì¼ì˜ GCS URI (gs://bucket/path)
    """
    try:
        # ì¸ì¦ ì„¤ì • ì‹œë„ (ë¡œì»¬ í™˜ê²½ì—ì„œë§Œ)
        setup_credentials()
        
        storage_client = storage.Client(project=project)
        bucket = storage_client.bucket(bucket_name)
        blob = bucket.blob(destination_blob_name)
        
        # íŒŒì¼ ì¡´ì¬ í™•ì¸
        source_path = Path(source_file)
        if not source_path.exists():
            raise FileNotFoundError(f"ì†ŒìŠ¤ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {source_file}")
        
        logger.info(f"íŒŒì¼ ì—…ë¡œë“œ ì¤‘: {source_file} -> gs://{bucket_name}/{destination_blob_name}")
        
        # íŒŒì¼ ì—…ë¡œë“œ
        blob.upload_from_filename(str(source_path))
        
        gcs_uri = f"gs://{bucket_name}/{destination_blob_name}"
        logger.info(f"âœ… íŒŒì¼ ì—…ë¡œë“œ ì™„ë£Œ: {gcs_uri}")
        
        return gcs_uri
        
    except Exception as e:
        logger.error(f"âŒ íŒŒì¼ ì—…ë¡œë“œ ì‹¤íŒ¨: {e}")
        raise


def ensure_bucket_exists(bucket_name: str, project: str) -> bool:
    """ë²„í‚·ì´ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸í•˜ê³ , ì—†ìœ¼ë©´ ìƒì„±í•©ë‹ˆë‹¤."""
    try:
        # ì¸ì¦ ì„¤ì • ì‹œë„ (ë¡œì»¬ í™˜ê²½ì—ì„œë§Œ)
        setup_credentials()
        
        # ì¸ì¦ í™•ì¸
        try:
            storage_client = storage.Client(project=project)
        except Exception as auth_error:
            error_msg = str(auth_error)
            # Docker í™˜ê²½ì—ì„œ ë¡œì»¬ ê²½ë¡œ ì—ëŸ¬ê°€ ë‚˜ëŠ” ê²½ìš° ë” ëª…í™•í•œ ë©”ì‹œì§€
            if "was not found" in error_msg or "File" in error_msg:
                logger.error(f"âŒ Google Cloud ì¸ì¦ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                logger.error("Docker í™˜ê²½ì—ì„œëŠ” í™˜ê²½ ë³€ìˆ˜ë¡œ ì¸ì¦ ì •ë³´ë¥¼ ì œê³µí•´ì•¼ í•©ë‹ˆë‹¤:")
                logger.error("  1. GOOGLE_APPLICATION_CREDENTIALS í™˜ê²½ ë³€ìˆ˜ì— ì¸ì¦ íŒŒì¼ ê²½ë¡œ ì„¤ì •")
                logger.error("  2. ë˜ëŠ” docker-compose.ymlì—ì„œ ì¸ì¦ íŒŒì¼ì„ ë³¼ë¥¨ ë§ˆìš´íŠ¸")
                logger.error("  3. ë˜ëŠ” ì„œë¹„ìŠ¤ ê³„ì • í‚¤ë¥¼ í™˜ê²½ ë³€ìˆ˜ë¡œ ì§ì ‘ ì„¤ì •")
            else:
                logger.error(f"âŒ Google Cloud ì¸ì¦ ì‹¤íŒ¨: {auth_error}")
                logger.error("ì¸ì¦ ë°©ë²•:")
                logger.error("  1. GOOGLE_APPLICATION_CREDENTIALS í™˜ê²½ ë³€ìˆ˜ ì„¤ì •")
                logger.error("  2. gcloud auth application-default login ì‹¤í–‰")
            raise
        
        bucket = storage_client.bucket(bucket_name)
        if bucket.exists():
            logger.info(f"âœ… ë²„í‚·ì´ ì´ë¯¸ ì¡´ì¬í•©ë‹ˆë‹¤: {bucket_name}")
            return True
        
        # ë²„í‚· ìƒì„±
        logger.info(f"ë²„í‚·ì´ ì—†ìŠµë‹ˆë‹¤. ìƒì„± ì¤‘: {bucket_name}")
        try:
            bucket = storage_client.create_bucket(bucket_name)
            logger.info(f"âœ… ë²„í‚· ìƒì„± ì™„ë£Œ: {bucket_name}")
            return True
        except Exception as create_error:
            logger.error(f"âŒ ë²„í‚· ìƒì„± ì‹¤íŒ¨: {create_error}")
            logger.error("ë²„í‚· ìƒì„± ê¶Œí•œì´ ì—†ê±°ë‚˜ ì´ë¯¸ ë‹¤ë¥¸ í”„ë¡œì íŠ¸ì— ì¡´ì¬í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
            raise
        
    except Exception as e:
        logger.error(f"âŒ ë²„í‚· í™•ì¸/ìƒì„± ì‹¤íŒ¨: {e}")
        import traceback
        logger.error(traceback.format_exc())
        raise


def get_current_version(bucket_name: str, project: str, base_name: str = "predict-package") -> int:
    """GCSì—ì„œ í˜„ì¬ íŒ¨í‚¤ì§€ ë²„ì „ì„ ê°€ì ¸ì˜µë‹ˆë‹¤. ì—†ìœ¼ë©´ 0ì„ ë°˜í™˜."""
    try:
        # ì¸ì¦ ì„¤ì • ì‹œë„ (ë¡œì»¬ í™˜ê²½ì—ì„œë§Œ)
        setup_credentials()
        
        storage_client = storage.Client(project=project)
        bucket = storage_client.bucket(bucket_name)
        
        # ë²„ì „ íŒŒì¼ ì½ê¸°
        version_file_name = f"{base_name}-version.json"
        version_blob = bucket.blob(version_file_name)
        if version_blob.exists():
            version_data = json.loads(version_blob.download_as_text())
            current_version = version_data.get("version", 0)
            logger.info(f"ğŸ“‹ ë²„ì „ íŒŒì¼ì—ì„œ í™•ì¸: v{current_version} ({version_file_name})")
            return current_version
        
        # ë²„ì „ íŒŒì¼ì´ ì—†ìœ¼ë©´ ê¸°ì¡´ íŒ¨í‚¤ì§€ íŒŒì¼ì—ì„œ ìµœëŒ€ ë²„ì „ ì°¾ê¸°
        logger.info(f"ğŸ“‹ ë²„ì „ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤. ê¸°ì¡´ íŒ¨í‚¤ì§€ì—ì„œ ìµœëŒ€ ë²„ì „ì„ ì°¾ëŠ” ì¤‘... (prefix: {base_name}-v)")
        blobs = list(bucket.list_blobs(prefix=f"packages/{base_name}-v"))
        
        max_version = 0
        version_pattern = re.compile(rf'{re.escape(base_name)}-v(\d+)\.tar\.gz')
        found_versions = []
        
        for blob in blobs:
            match = version_pattern.search(blob.name)
            if match:
                version = int(match.group(1))
                found_versions.append(version)
                max_version = max(max_version, version)
        
        if max_version > 0:
            found_versions.sort()
            logger.info(f"ğŸ“‹ ê¸°ì¡´ íŒ¨í‚¤ì§€ì—ì„œ ë°œê²¬ëœ ë²„ì „ë“¤: {found_versions}")
            logger.info(f"ğŸ“‹ ìµœëŒ€ ë²„ì „: v{max_version}")
            return max_version
        
        logger.info("ğŸ“‹ ê¸°ì¡´ íŒ¨í‚¤ì§€ê°€ ì—†ìŠµë‹ˆë‹¤. ë²„ì „ 0ë¶€í„° ì‹œì‘í•©ë‹ˆë‹¤.")
        return 0
        
    except Exception as e:
        logger.warning(f"âš ï¸ ë²„ì „ í™•ì¸ ì¤‘ ì˜¤ë¥˜ (ê¸°ë³¸ê°’ 0 ì‚¬ìš©): {e}")
        return 0


def save_version(bucket_name: str, version: int, project: str, base_name: str = "predict-package") -> None:
    """GCSì— íŒ¨í‚¤ì§€ ë²„ì „ì„ ì €ì¥í•©ë‹ˆë‹¤."""
    try:
        # ì¸ì¦ ì„¤ì • ì‹œë„ (ë¡œì»¬ í™˜ê²½ì—ì„œë§Œ)
        setup_credentials()
        
        storage_client = storage.Client(project=project)
        bucket = storage_client.bucket(bucket_name)
        
        version_data = {
            "version": version,
            "updated_at": datetime.utcnow().isoformat()
        }
        
        version_file_name = f"{base_name}-version.json"
        version_blob = bucket.blob(version_file_name)
        version_blob.upload_from_string(
            json.dumps(version_data, indent=2),
            content_type="application/json"
        )
        logger.info(f"ğŸ’¾ ë²„ì „ ì •ë³´ ì €ì¥ ì™„ë£Œ: v{version} ({version_file_name})")
        
    except Exception as e:
        logger.error(f"âŒ ë²„ì „ ì €ì¥ ì‹¤íŒ¨: {e}")
        raise


def build_package_from_script(
    script_path: str,
    output_path: Optional[str] = None
) -> str:
    """
    predict.py ìŠ¤í¬ë¦½íŠ¸ë¥¼ Vertex AI CustomJob í˜•ì‹ì˜ tar.gz íŒ¨í‚¤ì§€ë¡œ ë¹Œë“œí•©ë‹ˆë‹¤.
    
    Args:
        script_path: ë¹Œë“œí•  Python ìŠ¤í¬ë¦½íŠ¸ ê²½ë¡œ (ì˜ˆ: predict.py)
        output_path: ì¶œë ¥ tar.gz íŒŒì¼ ê²½ë¡œ (Noneì´ë©´ ì„ì‹œ íŒŒì¼ ìƒì„±)
    
    Returns:
        ìƒì„±ëœ tar.gz íŒŒì¼ ê²½ë¡œ
    """
    script_path_obj = Path(script_path)
    if not script_path_obj.exists():
        raise FileNotFoundError(f"ìŠ¤í¬ë¦½íŠ¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {script_path}")
    
    # ì„ì‹œ ë””ë ‰í† ë¦¬ ìƒì„±
    with tempfile.TemporaryDirectory() as temp_dir:
        temp_path = Path(temp_dir)
        
        # íŒ¨í‚¤ì§€ ë””ë ‰í† ë¦¬ êµ¬ì¡° ìƒì„±
        package_dir = temp_path / "aiplatform_custom_trainer_script"
        package_dir.mkdir()
        
        # __init__.py ìƒì„±
        (package_dir / "__init__.py").write_text("")
        
        # task.py ìƒì„± (predict.py ë‚´ìš© ë³µì‚¬)
        script_content = script_path_obj.read_text(encoding='utf-8')
        (package_dir / "task.py").write_text(script_content, encoding='utf-8')
        
        # setup.py ìƒì„± (í•„ìš”í•œ íŒ¨í‚¤ì§€ í¬í•¨)
        required_packages = [
            "supabase>=2.0.0",
            "pandas>=2.0.0",
            "numpy>=1.24.0",
            "scikit-learn>=1.3.0",
            "tensorflow>=2.11.0",
            "matplotlib>=3.7.0",
            "pymongo>=4.6.0",  # MongoDB ì—°ê²°ìš©
        ]
        
        setup_py_content = f"""from setuptools import setup, find_packages

setup(
    name="aiplatform_custom_trainer_script",
    version="0.1",
    packages=find_packages(),
    install_requires={required_packages},
)
"""
        (temp_path / "setup.py").write_text(setup_py_content, encoding='utf-8')
        
        # MANIFEST.in ìƒì„±
        manifest_content = """include aiplatform_custom_trainer_script/*.py
"""
        (temp_path / "MANIFEST.in").write_text(manifest_content, encoding='utf-8')
        
        # tar.gz íŒŒì¼ ìƒì„±
        if output_path is None:
            output_file = tempfile.NamedTemporaryFile(delete=False, suffix='.tar.gz')
            output_path = output_file.name
            output_file.close()
        
        output_path_obj = Path(output_path)
        
        # tar.gz ì••ì¶•
        with tarfile.open(output_path_obj, "w:gz") as tar:
            tar.add(temp_path / "setup.py", arcname="setup.py")
            tar.add(temp_path / "MANIFEST.in", arcname="MANIFEST.in")
            tar.add(package_dir, arcname="aiplatform_custom_trainer_script")
        
        logger.info(f"âœ… íŒ¨í‚¤ì§€ ë¹Œë“œ ì™„ë£Œ: {output_path}")
        return str(output_path_obj)


def upload_package_with_version(
    bucket_name: str,
    source_file: str,
    project: str,
    base_name: str = "predict-package",
    build_from_script: bool = False
) -> tuple[str, int]:
    """
    íŒ¨í‚¤ì§€ë¥¼ ë²„ì „ ë²ˆí˜¸ì™€ í•¨ê»˜ GCSì— ì—…ë¡œë“œí•©ë‹ˆë‹¤.
    
    Args:
        bucket_name: GCS ë²„í‚· ì´ë¦„
        source_file: ì—…ë¡œë“œí•  íŒŒì¼ ê²½ë¡œ (tar.gz ë˜ëŠ” .py ìŠ¤í¬ë¦½íŠ¸)
        project: Google Cloud í”„ë¡œì íŠ¸ ID
        base_name: íŒ¨í‚¤ì§€ ê¸°ë³¸ ì´ë¦„
        build_from_script: Trueì´ë©´ source_fileì„ .py ìŠ¤í¬ë¦½íŠ¸ë¡œ ê°„ì£¼í•˜ê³  ë¹Œë“œ
    
    Returns:
        (íŒ¨í‚¤ì§€ GCS URI, ë²„ì „ ë²ˆí˜¸) íŠœí”Œ
    """
    # í˜„ì¬ ë²„ì „ ê°€ì ¸ì˜¤ê¸° (ì—…ë¡œë“œ ì „ ë²„ì „ ì²´í¬)
    logger.info("=" * 60)
    logger.info("ğŸ“¦ íŒ¨í‚¤ì§€ ì—…ë¡œë“œ ì‹œì‘")
    logger.info("=" * 60)
    logger.info(f"  ë²„í‚·: {bucket_name}")
    logger.info(f"  ì†ŒìŠ¤ íŒŒì¼: {source_file}")
    logger.info(f"  ê¸°ë³¸ ì´ë¦„: {base_name}")
    
    current_version = get_current_version(bucket_name, project, base_name)
    logger.info(f"  âœ… í˜„ì¬ ìµœì‹  ë²„ì „: v{current_version}")
    
    # ìƒˆ ë²„ì „ (í˜„ì¬ ë²„ì „ + 1)
    new_version = current_version + 1
    logger.info(f"  ğŸ†• ìƒˆ ë²„ì „: v{new_version}")
    
    # ìƒˆ íŒ¨í‚¤ì§€ ì´ë¦„
    package_name = f"{base_name}-v{new_version}.tar.gz"
    package_path = f"packages/{package_name}"
    logger.info(f"  ğŸ“ íŒ¨í‚¤ì§€ ê²½ë¡œ: {package_path}")
    logger.info("=" * 60)
    
    # ìŠ¤í¬ë¦½íŠ¸ì—ì„œ ë¹Œë“œí•´ì•¼ í•˜ëŠ” ê²½ìš°
    temp_package_path = None
    if build_from_script or source_file.endswith('.py'):
        logger.info(f"ìŠ¤í¬ë¦½íŠ¸ì—ì„œ íŒ¨í‚¤ì§€ ë¹Œë“œ ì¤‘: {source_file}")
        temp_package_path = build_package_from_script(source_file)
        source_file = temp_package_path
    
    try:
        # íŒŒì¼ ì—…ë¡œë“œ
        gcs_uri = upload_file_to_gcs(
            bucket_name=bucket_name,
            source_file=source_file,
            destination_blob_name=package_path,
            project=project
        )
        
        # ë²„ì „ ì •ë³´ ì €ì¥
        save_version(bucket_name, new_version, project, base_name)
        
        logger.info("=" * 60)
        logger.info("âœ… íŒ¨í‚¤ì§€ ì—…ë¡œë“œ ì™„ë£Œ")
        logger.info("=" * 60)
        logger.info(f"  ë²„ì „: v{new_version}")
        logger.info(f"  GCS URI: {gcs_uri}")
        logger.info("=" * 60)
        
        return gcs_uri, new_version
    finally:
        # ì„ì‹œ íŒŒì¼ ì •ë¦¬
        if temp_package_path and os.path.exists(temp_package_path):
            try:
                os.unlink(temp_package_path)
            except Exception as e:
                logger.warning(f"ì„ì‹œ íŒŒì¼ ì‚­ì œ ì‹¤íŒ¨: {e}")


def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    parser = argparse.ArgumentParser(description="predict.py íŒ¨í‚¤ì§€ë¥¼ ë²„ì „ ê´€ë¦¬í•˜ì—¬ GCSì— ì—…ë¡œë“œ")
    parser.add_argument(
        "--file",
        type=str,
        default="predict.py",
        help="ì—…ë¡œë“œí•  íŒŒì¼ ê²½ë¡œ (ê¸°ë³¸ê°’: predict.py, .py íŒŒì¼ì´ë©´ ìë™ ë¹Œë“œ, .tar.gz íŒŒì¼ë„ ì§€ì›)"
    )
    parser.add_argument(
        "--build",
        action="store_true",
        help=".py ìŠ¤í¬ë¦½íŠ¸ë¥¼ ìë™ìœ¼ë¡œ ë¹Œë“œí•˜ì—¬ ì—…ë¡œë“œ (ê¸°ë³¸ê°’: ìë™ ê°ì§€)"
    )
    parser.add_argument(
        "--bucket",
        type=str,
        default=None,
        help="GCS ë²„í‚· ì´ë¦„ (ê¸°ë³¸ê°’: í™˜ê²½ ë³€ìˆ˜ GCP_BUCKET_NAME ë˜ëŠ” stock-trading-packages)"
    )
    parser.add_argument(
        "--project",
        type=str,
        default=None,
        help="Google Cloud í”„ë¡œì íŠ¸ ID (ê¸°ë³¸ê°’: í™˜ê²½ ë³€ìˆ˜ GCP_PROJECT_ID)"
    )
    parser.add_argument(
        "--base-name",
        type=str,
        default="predict-package",
        help="íŒ¨í‚¤ì§€ ê¸°ë³¸ ì´ë¦„ (ê¸°ë³¸ê°’: predict-package, ê²°ê³¼: predict-package-v1.tar.gz)"
    )
    parser.add_argument(
        "--no-version",
        action="store_true",
        help="ë²„ì „ ê´€ë¦¬ ì—†ì´ ì§ì ‘ ì—…ë¡œë“œ (ê¸°ì¡´ ë°©ì‹)"
    )
    parser.add_argument(
        "--path",
        type=str,
        default=None,
        help="GCS ë‚´ ì§ì ‘ ê²½ë¡œ ì§€ì • (--no-version ì‚¬ìš© ì‹œ)"
    )
    
    args = parser.parse_args()
    
    # í”„ë¡œì íŠ¸ ID í™•ì¸
    project = args.project or os.getenv("GCP_PROJECT_ID")
    if not project:
        logger.error("âŒ GCP_PROJECT_ID í™˜ê²½ ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ê±°ë‚˜ --project ì¸ìë¥¼ ì œê³µí•˜ì„¸ìš”.")
        sys.exit(1)
    
    # ë²„í‚· ì´ë¦„ í™•ì¸
    bucket_name = args.bucket or os.getenv("GCP_BUCKET_NAME", "stock-trading-packages")
    if bucket_name.startswith("gs://"):
        bucket_name = bucket_name[5:]
    
    # ì†ŒìŠ¤ íŒŒì¼ ê²½ë¡œ í™•ì¸
    source_file = Path(args.file)
    if not source_file.is_absolute():
        # ê¸°ë³¸ê°’ì´ predict.pyì¸ ê²½ìš° scripts/utils/predict.pyë¥¼ ì°¾ìŒ
        if args.file == "predict.py":
            source_file = Path(__file__).parent / "predict.py"
        else:
            source_file = Path(__file__).parent / source_file
    
    if not source_file.exists():
        logger.error(f"âŒ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {source_file}")
        sys.exit(1)
    
    logger.info("=" * 60)
    logger.info("GCS íŒ¨í‚¤ì§€ ì—…ë¡œë“œ ì‹œì‘")
    logger.info("=" * 60)
    logger.info(f"í”„ë¡œì íŠ¸: {project}")
    logger.info(f"ë²„í‚·: {bucket_name}")
    logger.info(f"ì†ŒìŠ¤ íŒŒì¼: {source_file}")
    logger.info("=" * 60)
    
    # ë²„í‚· ì¡´ì¬ í™•ì¸ ë° ìƒì„±
    if not ensure_bucket_exists(bucket_name, project):
        logger.error("ë²„í‚·ì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        sys.exit(1)
    
    # íŒŒì¼ ì—…ë¡œë“œ
    try:
        if args.no_version:
            # ë²„ì „ ê´€ë¦¬ ì—†ì´ ì§ì ‘ ì—…ë¡œë“œ
            if not args.path:
                logger.error("âŒ --no-version ì‚¬ìš© ì‹œ --path ì¸ìê°€ í•„ìš”í•©ë‹ˆë‹¤.")
                sys.exit(1)
            
            gcs_uri = upload_file_to_gcs(
                bucket_name=bucket_name,
                source_file=str(source_file),
                destination_blob_name=args.path,
                project=project
            )
            
            logger.info("=" * 60)
            logger.info("âœ… ì—…ë¡œë“œ ì™„ë£Œ!")
            logger.info(f"GCS URI: {gcs_uri}")
            logger.info("=" * 60)
        else:
            # ë²„ì „ ê´€ë¦¬ì™€ í•¨ê»˜ ì—…ë¡œë“œ
            # .py íŒŒì¼ì´ë©´ ìë™ìœ¼ë¡œ ë¹Œë“œ
            build_from_script = args.build or str(source_file).endswith('.py')
            
            gcs_uri, version = upload_package_with_version(
                bucket_name=bucket_name,
                source_file=str(source_file),
                project=project,
                base_name=args.base_name,
                build_from_script=build_from_script
            )
            
            logger.info("=" * 60)
            logger.info("âœ… ì—…ë¡œë“œ ì™„ë£Œ!")
            logger.info(f"íŒ¨í‚¤ì§€ ë²„ì „: v{version}")
            logger.info(f"GCS URI: {gcs_uri}")
            logger.info(f"ë‹¤ìŒ ì‹¤í–‰ ì‹œ ìë™ìœ¼ë¡œ v{version}ì´ ì‚¬ìš©ë©ë‹ˆë‹¤.")
            logger.info("=" * 60)
        
    except Exception as e:
        logger.error(f"âŒ ì—…ë¡œë“œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)


if __name__ == "__main__":
    main()