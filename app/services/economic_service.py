import pandas as pd
from app.db.supabase import supabase
# stock.pyëŠ” ì•„ì§ ëª¨ë“ˆë¡œ ì˜®ê¸°ì§€ ì•Šì•˜ìœ¼ë¯€ë¡œ ê¸°ì¡´ ì„í¬íŠ¸ ìœ ì§€
from stock import collect_economic_data
import stock
import numpy as np
from datetime import datetime, timedelta
import pytz
from app.core.config import settings
from fastapi import APIRouter, BackgroundTasks, HTTPException, Depends
from app.services.stock_recommendation_service import StockRecommendationService
import httpx
import time

def get_last_updated_date():
    """
    ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ë§ˆì§€ë§‰ìœ¼ë¡œ ìˆ˜ì§‘ëœ ë‚ ì§œë¥¼ ì¡°íšŒí•©ë‹ˆë‹¤.
    """
    try:
        # ë‚ ì§œ ì»¬ëŸ¼ëª…ì„ ì˜¬ë°”ë¥´ê²Œ ìˆ˜ì •
        response = supabase.table("economic_and_stock_data").select("ë‚ ì§œ").order("ë‚ ì§œ", desc=True).limit(1).execute()
        
        if response.data and len(response.data) > 0:
            last_date = datetime.fromisoformat(response.data[0]["ë‚ ì§œ"].replace('Z', '+00:00'))
            # ë‹¤ìŒ ë‚ ì§œ ë°˜í™˜
            next_date = (last_date + timedelta(days=1)).strftime('%Y-%m-%d')
            print(f"ë§ˆì§€ë§‰ ìˆ˜ì§‘ ë‚ ì§œ: {last_date.strftime('%Y-%m-%d')}, ë‹¤ìŒ ìˆ˜ì§‘ ì‹œì‘ì¼: {next_date}")
            return next_date
        else:
            # ë°ì´í„°ê°€ ì—†ìœ¼ë©´ ê¸°ë³¸ ì‹œì‘ ë‚ ì§œ ë°˜í™˜ (2006-01-01)
            print("ê¸°ì¡´ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. ê¸°ë³¸ ì‹œì‘ ë‚ ì§œ(2006-01-01)ë¡œ ì„¤ì •í•©ë‹ˆë‹¤.")
            return "2006-01-01"
    except Exception as e:
        print(f"ë§ˆì§€ë§‰ ìˆ˜ì§‘ ë‚ ì§œ ì¡°íšŒ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        # ì˜¤ë¥˜ ë°œìƒ ì‹œ ê¸°ë³¸ ì‹œì‘ ë‚ ì§œ ë°˜í™˜
        return "2006-01-01"

def get_existing_data_with_nulls():
    """
    NULL ê°’ì´ ìˆëŠ” ê¸°ì¡´ ë°ì´í„°ë¥¼ ì¡°íšŒí•©ë‹ˆë‹¤.
    """
    try:
        # NULL ê°’ì´ ìˆëŠ” ë ˆì½”ë“œë§Œ ì¡°íšŒ (PostgreSQLì˜ JSON ì—°ì‚°ì ì‚¬ìš©)
        query = "SELECT * FROM economic_and_stock_data WHERE jsonb_object_keys(data::jsonb) @> '{null}'::jsonb"
        response = supabase.table("economic_and_stock_data").select("*").execute(query)
        
        if response.data and len(response.data) > 0:
            # Pandas DataFrameìœ¼ë¡œ ë³€í™˜
            df = pd.DataFrame(response.data)
            print(f"NULL ê°’ì´ í¬í•¨ëœ ë ˆì½”ë“œ {len(df)}ê°œë¥¼ ì°¾ì•˜ìŠµë‹ˆë‹¤.")
            return df
        else:
            print("NULL ê°’ì´ í¬í•¨ëœ ë ˆì½”ë“œê°€ ì—†ìŠµë‹ˆë‹¤.")
            return pd.DataFrame()
    except Exception as e:
        print(f"NULL ê°’ ë°ì´í„° ì¡°íšŒ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        return pd.DataFrame()

# ì£¼ê°€ ê´€ë ¨ ì»¬ëŸ¼ ëª©ë¡ì„ stock_ticker_mapping í…Œì´ë¸”ì—ì„œ ë™ì ìœ¼ë¡œ ê°€ì ¸ì˜¤ê¸°
def get_active_stock_columns():
    """
    stock_ticker_mapping í…Œì´ë¸”ì—ì„œ is_active=trueì¸ ì£¼ì‹ ëª©ë¡ì„ ê°€ì ¸ì˜µë‹ˆë‹¤.
    ETFì™€ ê²½ì œ ì§€í‘œëŠ” ë³„ë„ë¡œ í¬í•¨í•©ë‹ˆë‹¤.
    """
    try:
        # í™œì„±í™”ëœ ì£¼ì‹ ëª©ë¡ ê°€ì ¸ì˜¤ê¸°
        mapping_response = supabase.table("stock_ticker_mapping").select("stock_name").eq("is_active", True).execute()
        active_stock_names = [item["stock_name"] for item in mapping_response.data]
        
        # ê²½ì œ ì§€í‘œ ë° ETFëŠ” í•­ìƒ í¬í•¨
        economic_and_etf_columns = [
            "ë‚˜ìŠ¤ë‹¥ ì¢…í•©ì§€ìˆ˜", "S&P 500 ì§€ìˆ˜", "ê¸ˆ ê°€ê²©", "ë‹¬ëŸ¬ ì¸ë±ìŠ¤", "ë‚˜ìŠ¤ë‹¥ 100", 
            "S&P 500 ETF", "QQQ ETF", "ëŸ¬ì…€ 2000 ETF", "ë‹¤ìš° ì¡´ìŠ¤ ETF", "VIX ì§€ìˆ˜", 
            "ë‹›ì¼€ì´ 225", "ìƒí•´ì¢…í•©", "í•­ì…", "ì˜êµ­ FTSE", "ë…ì¼ DAX", "í”„ë‘ìŠ¤ CAC 40", 
            "ë¯¸êµ­ ì „ì²´ ì±„ê¶Œì‹œì¥ ETF", "TIPS ETF", "íˆ¬ìë“±ê¸‰ íšŒì‚¬ì±„ ETF", "ë‹¬ëŸ¬/ì—”", "ë‹¬ëŸ¬/ìœ„ì•ˆ",
            "ë¯¸êµ­ ë¦¬ì¸  ETF"
        ]
        
        # í™œì„±í™”ëœ ì£¼ì‹ + ê²½ì œ ì§€í‘œ/ETF í•©ì¹˜ê¸°
        all_stock_columns = economic_and_etf_columns + active_stock_names
        
        print(f"í™œì„±í™”ëœ ì£¼ì‹ {len(active_stock_names)}ê°œë¥¼ stock_ticker_mappingì—ì„œ ê°€ì ¸ì™”ìŠµë‹ˆë‹¤.")
        return all_stock_columns
    except Exception as e:
        print(f"âš ï¸ ê²½ê³ : stock_ticker_mapping í…Œì´ë¸” ì¡°íšŒ ì‹¤íŒ¨: {str(e)}. ê¸°ë³¸ ëª©ë¡ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.")
        # ê¸°ë³¸ ëª©ë¡ (fallback)
        return [
            "ë‚˜ìŠ¤ë‹¥ ì¢…í•©ì§€ìˆ˜", "S&P 500 ì§€ìˆ˜", "ê¸ˆ ê°€ê²©", "ë‹¬ëŸ¬ ì¸ë±ìŠ¤", "ë‚˜ìŠ¤ë‹¥ 100", 
            "S&P 500 ETF", "QQQ ETF", "ëŸ¬ì…€ 2000 ETF", "ë‹¤ìš° ì¡´ìŠ¤ ETF", "VIX ì§€ìˆ˜", 
            "ë‹›ì¼€ì´ 225", "ìƒí•´ì¢…í•©", "í•­ì…", "ì˜êµ­ FTSE", "ë…ì¼ DAX", "í”„ë‘ìŠ¤ CAC 40", 
            "ë¯¸êµ­ ì „ì²´ ì±„ê¶Œì‹œì¥ ETF", "TIPS ETF", "íˆ¬ìë“±ê¸‰ íšŒì‚¬ì±„ ETF", "ë‹¬ëŸ¬/ì—”", "ë‹¬ëŸ¬/ìœ„ì•ˆ",
            "ë¯¸êµ­ ë¦¬ì¸  ETF", "ì• í”Œ", "ë§ˆì´í¬ë¡œì†Œí”„íŠ¸", "ì•„ë§ˆì¡´", "êµ¬ê¸€ A", "êµ¬ê¸€ C", "ë©”íƒ€", 
            "í…ŒìŠ¬ë¼", "ì—”ë¹„ë””ì•„", "ì¸í…”", "ë§ˆì´í¬ë¡ ", "ë¸Œë¡œë“œì»´", 
            "í…ì‚¬ìŠ¤ ì¸ìŠ¤íŠ¸ë£¨ë¨¼íŠ¸", "AMD", "ì–´í”Œë¼ì´ë“œ ë¨¸í‹°ë¦¬ì–¼ì¦ˆ",
            "ì…€ë ˆìŠ¤í‹°ì¹´", "ë²„í‹°ë¸Œ í™€ë”©ìŠ¤", "ë¹„ìŠ¤íŠ¸ë¼ ì—ë„ˆì§€", "ë¸”ë£¸ì—ë„ˆì§€", "ì˜¤í´ë¡œ", "íŒ”ë€í‹°ì–´",
            "ì„¸ì¼ì¦ˆí¬ìŠ¤", "ì˜¤ë¼í´", "ì•±í”Œë¡œë¹ˆ", "íŒ”ë¡œì•Œí†  ë„¤íŠ¸ì›ìŠ¤", "í¬ë¼ìš°ë“œ ìŠ¤íŠ¸ë¼ì´í¬",
            "ìŠ¤ë…¸ìš°í”Œë ˆì´í¬", "TSMC", "í¬ë¦¬ë„ í…Œí¬ë†€ë¡œì§€ ê·¸ë£¹ í™€ë”©", "ë¡œë¹ˆí›„ë“œ", "ì¼ë¼ì´ë¦´ë¦¬",
            "ì›”ë§ˆíŠ¸", "ì¡´ìŠ¨ì•¤ì¡´ìŠ¨"
        ]

# ì£¼ê°€ ê´€ë ¨ ì»¬ëŸ¼ ëª©ë¡ (ë™ì ìœ¼ë¡œ ê°€ì ¸ì˜´)
stock_columns = get_active_stock_columns()

# ê²½ì œ ì§€í‘œ ì»¬ëŸ¼ ëª©ë¡ ì •ì˜
economic_columns = [
    "10ë…„ ê¸°ëŒ€ ì¸í”Œë ˆì´ì…˜ìœ¨", "ì¥ë‹¨ê¸° ê¸ˆë¦¬ì°¨", "ê¸°ì¤€ê¸ˆë¦¬", "ë¯¸ì‹œê°„ëŒ€ ì†Œë¹„ì ì‹¬ë¦¬ì§€ìˆ˜", 
    "ì‹¤ì—…ë¥ ", "2ë…„ ë§Œê¸° ë¯¸êµ­ êµ­ì±„ ìˆ˜ìµë¥ ", "10ë…„ ë§Œê¸° ë¯¸êµ­ êµ­ì±„ ìˆ˜ìµë¥ ", "ê¸ˆìœµìŠ¤íŠ¸ë ˆìŠ¤ì§€ìˆ˜", 
    "ê°œì¸ ì†Œë¹„ ì§€ì¶œ", "ì†Œë¹„ì ë¬¼ê°€ì§€ìˆ˜", "5ë…„ ë³€ë™ê¸ˆë¦¬ ëª¨ê¸°ì§€", "ë¯¸êµ­ ë‹¬ëŸ¬ í™˜ìœ¨", 
    "í†µí™” ê³µê¸‰ëŸ‰ M2", "ê°€ê³„ ë¶€ì±„ ë¹„ìœ¨", "GDP ì„±ì¥ë¥ "
]

async def update_economic_data_in_background():
    """
    ë°±ê·¸ë¼ìš´ë“œì—ì„œ ê²½ì œ ì§€í‘œ ë°ì´í„°ë¥¼ ì—…ë°ì´íŠ¸
    """
    try:
        print("ê²½ì œ ì§€í‘œ ë° ì£¼ê°€ ë°ì´í„° ì—…ë°ì´íŠ¸ ì‘ì—… ì‹œì‘...")
        
        # ë¯¸êµ­ ì¥ ë§ˆê° ì—¬ë¶€ í™•ì¸ (ë‰´ìš• ì‹œê°„ ê¸°ì¤€ìœ¼ë¡œ ì •í™•íˆ ì²´í¬)
        now_korea = datetime.now(pytz.timezone('Asia/Seoul'))
        now_ny = datetime.now(pytz.timezone('America/New_York'))
        
        korea_time = now_korea.strftime('%H:%M')
        ny_hour = now_ny.hour
        ny_minute = now_ny.minute
        ny_weekday = now_ny.weekday()  # 0=ì›”ìš”ì¼, 6=ì¼ìš”ì¼
        
        # ë¯¸êµ­ ì£¼ì‹ ì‹œì¥ì€ í‰ì¼(ì›”-ê¸ˆ) 9:30 AM - 4:00 PM ET
        is_weekday = 0 <= ny_weekday <= 4  # ì›”ìš”ì¼ì—ì„œ ê¸ˆìš”ì¼ê¹Œì§€
        is_market_open_time = (
            (ny_hour == 9 and ny_minute >= 30) or
            (10 <= ny_hour < 16) or
            (ny_hour == 16 and ny_minute == 0)
        )
        
        is_market_hours = is_weekday and is_market_open_time
        
        # ë¯¸êµ­ ì£¼ì‹ ì‹œì¥ì´ ì—´ë ¤ ìˆëŠ” ê²½ìš°ì—ë§Œ ë°ì´í„° ìˆ˜ì§‘ ì—°ê¸°
        # ì¥ì´ ë§ˆê°ëœ í›„(ë‰´ìš• ì‹œê°„ 16:00 ì´í›„) ë˜ëŠ” ì£¼ë§ì—ëŠ” ë°ì´í„° ìˆ˜ì§‘ ì§„í–‰
        if is_market_hours:
            print(f"í˜„ì¬ ì‹œê°„ (í•œêµ­: {korea_time}, ë‰´ìš•: {now_ny.strftime('%Y-%m-%d %H:%M')})ì€ ë¯¸êµ­ ì£¼ì‹ ì‹œì¥ ìš´ì˜ ì‹œê°„ì…ë‹ˆë‹¤.")
            print(f"ì¥ ë§ˆê° í›„(ë‰´ìš• ì‹œê°„ 16:00 ì´í›„)ì— ë°ì´í„°ë¥¼ ìˆ˜ì§‘í•©ë‹ˆë‹¤.")
            return
        
        print(f"í˜„ì¬ ì‹œê°„ (í•œêµ­: {korea_time}, ë‰´ìš•: {now_ny.strftime('%Y-%m-%d %H:%M')}) - ë¯¸êµ­ ì¥ ë§ˆê° ì‹œê°„ì´ë¯€ë¡œ ë°ì´í„° ìˆ˜ì§‘ì„ ì§„í–‰í•©ë‹ˆë‹¤.")

        # ë§ˆì§€ë§‰ ìˆ˜ì§‘ ë‚ ì§œ ì¡°íšŒ
        start_date = get_last_updated_date()
        
        # í•œêµ­ ì‹œê°„ëŒ€ ê¸°ì¤€ìœ¼ë¡œ í˜„ì¬ ë‚ ì§œ ê³„ì‚° (ì»¨í…Œì´ë„ˆ ì‹œê°„ëŒ€ ë¬¸ì œ ë°©ì§€)
        korea_tz = pytz.timezone('Asia/Seoul')
        now_korea_dt = datetime.now(korea_tz)
        today = now_korea_dt.strftime('%Y-%m-%d')
        yesterday = (now_korea_dt - timedelta(days=1)).strftime('%Y-%m-%d')
        
        print(f"í•œêµ­ ì‹œê°„ ê¸°ì¤€ ì˜¤ëŠ˜: {today}, ì–´ì œ: {yesterday}, ìˆ˜ì§‘ ì‹œì‘ì¼: {start_date}")
        
        # ìˆ˜ì§‘ ì‹œì‘ì¼ì´ ì˜¤ëŠ˜ë³´ë‹¤ í¬ë©´ ìˆ˜ì§‘í•  ë°ì´í„°ê°€ ì—†ìŒ
        if start_date > today:
            print(f"ìˆ˜ì§‘ ì‹œì‘ì¼({start_date})ì´ ì˜¤ëŠ˜({today})ë³´ë‹¤ í½ë‹ˆë‹¤. ìˆ˜ì§‘í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return {"success": True, "total_records": 0, "updated_records": 0}
        
        # ë°ì´í„° ìˆ˜ì§‘ì€ ì˜¤ëŠ˜ê¹Œì§€ í•˜ë˜, ì €ì¥ì€ ì–´ì œê¹Œì§€ë§Œ
        # start_dateê°€ yesterdayë³´ë‹¤ í¬ë©´, ì–´ì œ ë°ì´í„°ëŠ” ì´ë¯¸ ìˆ˜ì§‘ë˜ì—ˆìœ¼ë¯€ë¡œ ì˜¤ëŠ˜ ë°ì´í„°ë§Œ ìˆ˜ì§‘
        collection_end_date = today
        if start_date > yesterday:
            # ì–´ì œ ë°ì´í„°ëŠ” ì´ë¯¸ ìˆ˜ì§‘ë˜ì—ˆìœ¼ë¯€ë¡œ ì˜¤ëŠ˜ ë°ì´í„°ë§Œ ìˆ˜ì§‘ (ì €ì¥ì€ ë‚´ì¼)
            storage_end_date = yesterday
            print(f"ìˆ˜ì§‘ ì‹œì‘ì¼({start_date})ì´ ì–´ì œ({yesterday})ë³´ë‹¤ í¬ë¯€ë¡œ, ì˜¤ëŠ˜({today}) ë°ì´í„°ë§Œ ìˆ˜ì§‘í•©ë‹ˆë‹¤. (ì €ì¥ì€ ë‚´ì¼)")
        else:
            # ì–´ì œê¹Œì§€ì˜ ë°ì´í„°ë¥¼ ìˆ˜ì§‘í•˜ê³  ì €ì¥
            storage_end_date = yesterday
            print(f"ìˆ˜ì§‘ ì‹œì‘ì¼({start_date})ë¶€í„° ì–´ì œ({yesterday})ê¹Œì§€ì˜ ë°ì´í„°ë¥¼ ìˆ˜ì§‘í•˜ê³  ì €ì¥í•©ë‹ˆë‹¤.")
        
        # ì´ì „ ë°ì´í„° ê°€ì ¸ì˜¤ê¸° (ë§ˆì§€ë§‰ ìˆ˜ì§‘ ë‚ ì§œì˜ ë°ì´í„°)
        previous_date = (datetime.strptime(start_date, '%Y-%m-%d') - timedelta(days=1)).strftime('%Y-%m-%d')
        prev_data_response = supabase.table("economic_and_stock_data").select("*").eq("ë‚ ì§œ", previous_date).execute()
        previous_data = prev_data_response.data[0] if prev_data_response.data else {}
        
        # stock_columnsë¥¼ ìµœì‹  ìƒíƒœë¡œ ì—…ë°ì´íŠ¸ (ë§¤ë²ˆ ì‹¤í–‰ ì‹œ ìµœì‹  í™œì„±í™” ìƒíƒœ ë°˜ì˜)
        stock_columns = get_active_stock_columns()
        
        # ë°ì´í„° ìˆ˜ì§‘ (ì˜¤ëŠ˜ê¹Œì§€ ìˆ˜ì§‘)
        new_data = collect_economic_data(start_date=start_date, end_date=collection_end_date)
        
        # ë””ë²„ê¹…: ìˆ˜ì§‘ëœ ë°ì´í„° í™•ì¸
        print("\n=== ìˆ˜ì§‘ëœ ë°ì´í„° í™•ì¸ ===")
        print(f"í™œì„±í™”ëœ ì£¼ì‹ ì»¬ëŸ¼ ìˆ˜: {len(stock_columns)}")
        for date_idx in new_data.index[:3]:  # ì²˜ìŒ 3ê°œ ë‚ ì§œë§Œ
            date_str = date_idx.strftime('%Y-%m-%d') if isinstance(date_idx, pd.Timestamp) else date_idx
            print(f"ë‚ ì§œ: {date_str}")
            for stock in stock_columns[:5]:  # ëª‡ ê°œì˜ ì£¼ê°€ë§Œ ì¶œë ¥
                if stock in new_data.columns:
                    print(f"  {stock}: {new_data.loc[date_idx, stock]}")
        
        if new_data is None or new_data.empty:
            print("ìˆ˜ì§‘í•  ìƒˆ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return {"success": True, "total_records": 0, "updated_records": 0}
        
        # ë‚ ì§œ ë²”ìœ„ ìƒì„± (ì‹œì‘ì¼ë¶€í„° ì–´ì œê¹Œì§€ë§Œ)
        all_dates = pd.date_range(start=start_date, end=storage_end_date)
        saved_count = 0
        
        # ì¬ì‹œë„ ë¡œì§ì´ í¬í•¨ëœ ë°ì´í„° ì €ì¥ í•¨ìˆ˜ (ë£¨í”„ ë°–ìœ¼ë¡œ ì´ë™)
        def save_data_with_retry(date_str, data_dict, max_retries=3):
            """ë°ì´í„° ì €ì¥ì„ ì¬ì‹œë„í•˜ë©° ì²˜ë¦¬"""
            # ë°ì´í„° ë”•ì…”ë„ˆë¦¬ ê²€ì¦
            if not data_dict:
                print(f"âš ï¸ {date_str}: ì €ì¥í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤ (data_dictê°€ ë¹„ì–´ìˆìŒ)")
                return False
            
            # ë‚ ì§œëŠ” í•„ìˆ˜
            if not date_str:
                print(f"âš ï¸ ë‚ ì§œê°€ ì—†ì–´ì„œ ì €ì¥í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
                return False
            
            print(f"ğŸ“ {date_str}: ì €ì¥ ì‹œì‘ (ì»¬ëŸ¼ ìˆ˜: {len(data_dict)})")
            
            for attempt in range(max_retries):
                try:
                    # ê¸°ì¡´ ë°ì´í„° í™•ì¸
                    check = supabase.table("economic_and_stock_data").select("*").eq("ë‚ ì§œ", date_str).execute()
                    
                    # ì¤‘ë³µ ë°©ì§€ë¥¼ ìœ„í•´ ê¸°ì¡´ ë°ì´í„°ê°€ ìˆìœ¼ë©´ ì—…ë°ì´íŠ¸, ì—†ìœ¼ë©´ ì‚½ì…
                    if check.data and len(check.data) > 0:
                        # ê¸°ì¡´ ë ˆì½”ë“œê°€ ìˆëŠ” ê²½ìš°, null ê°’ë§Œ ì—…ë°ì´íŠ¸
                        existing_data = check.data[0]
                        update_dict = {}
                        
                        for col_name, value in data_dict.items():
                            # ê¸°ì¡´ ê°’ì´ nullì´ê±°ë‚˜ ëˆ„ë½ëœ ê²½ìš°ì—ë§Œ ì—…ë°ì´íŠ¸
                            if col_name not in existing_data or existing_data[col_name] is None:
                                update_dict[col_name] = value
                        
                        if update_dict:  # ì—…ë°ì´íŠ¸í•  ê°’ì´ ìˆëŠ” ê²½ìš°ì—ë§Œ
                            print(f"  â†’ {date_str}: ê¸°ì¡´ ë ˆì½”ë“œ ì—…ë°ì´íŠ¸ ({len(update_dict)}ê°œ ì»¬ëŸ¼)")
                            supabase.table("economic_and_stock_data").update(update_dict).eq("ë‚ ì§œ", date_str).execute()
                            print(f"  âœ… {date_str}: ì—…ë°ì´íŠ¸ ì„±ê³µ")
                        else:
                            print(f"  â„¹ï¸ {date_str}: ì—…ë°ì´íŠ¸í•  ë°ì´í„°ê°€ ì—†ìŒ (ëª¨ë“  ê°’ì´ ì´ë¯¸ ì¡´ì¬)")
                    else:
                        # ìƒˆ ë ˆì½”ë“œ ì¶”ê°€
                        insert_dict = {"ë‚ ì§œ": date_str}
                        insert_dict.update(data_dict)
                        print(f"  â†’ {date_str}: ìƒˆ ë ˆì½”ë“œ ì‚½ì… ({len(insert_dict)}ê°œ ì»¬ëŸ¼)")
                        supabase.table("economic_and_stock_data").insert(insert_dict).execute()
                        print(f"  âœ… {date_str}: ì‚½ì… ì„±ê³µ")
                    
                    return True  # ì„±ê³µ
                    
                except (httpx.RemoteProtocolError, httpx.ConnectError, httpx.TimeoutException) as e:
                    if attempt < max_retries - 1:
                        print(f"  âš ï¸ {date_str} ì €ì¥ ì‹¤íŒ¨ (ì‹œë„ {attempt+1}/{max_retries}): {str(e)}. ì¬ì‹œë„...")
                        time.sleep(2)  # ì¬ì‹œë„ ì „ ëŒ€ê¸°
                    else:
                        print(f"  âŒ {date_str} ì €ì¥ ìµœì¢… ì‹¤íŒ¨: {str(e)}")
                        import traceback
                        print(traceback.format_exc())
                        return False  # ì‹¤íŒ¨í•´ë„ ì˜ˆì™¸ë¥¼ ë°œìƒì‹œí‚¤ì§€ ì•ŠìŒ
                except Exception as e:
                    # ë‹¤ë¥¸ ì¢…ë¥˜ì˜ ì—ëŸ¬ëŠ” ì¦‰ì‹œ ì¬ì‹œë„
                    if attempt < max_retries - 1:
                        print(f"  âš ï¸ {date_str} ì €ì¥ ì‹¤íŒ¨ (ì‹œë„ {attempt+1}/{max_retries}): {str(e)}. ì¬ì‹œë„...")
                        time.sleep(2)  # ì¬ì‹œë„ ì „ ëŒ€ê¸°
                    else:
                        print(f"  âŒ {date_str} ì €ì¥ ìµœì¢… ì‹¤íŒ¨: {str(e)}")
                        import traceback
                        print(traceback.format_exc())
                        return False  # ì‹¤íŒ¨í•´ë„ ì˜ˆì™¸ë¥¼ ë°œìƒì‹œí‚¤ì§€ ì•ŠìŒ
            return False
        
        # ì–´ì œê¹Œì§€ ë‚ ì§œì— ëŒ€í•´ì„œë§Œ ì²˜ë¦¬
        for date in all_dates:
            try:
                date_str = date.strftime('%Y-%m-%d')
                
                # í•´ë‹¹ ë‚ ì§œì˜ ë°ì´í„°ê°€ ìˆ˜ì§‘ë˜ì—ˆëŠ”ì§€ í™•ì¸
                if date in new_data.index:
                    row = new_data.loc[date]
                    print(f"\n== {date_str} ë°ì´í„°ê°€ ìˆìŒ (ì €ì¥ ëŒ€ìƒ) ==")
                    # ì£¼ìš” ì£¼ê°€ ë°ì´í„° ëª‡ ê°œ ì¶œë ¥
                    for stock in stock_columns[:5]:
                        if stock in row.index:
                            print(f"  ì›ë³¸ {stock}: {row[stock]}")
                else:
                    print(f"\n== {date_str} ë°ì´í„°ê°€ ì—†ìŒ, ì´ì „ ë°ì´í„° ì‚¬ìš© (ì €ì¥ ëŒ€ìƒ) ==")
                    row = pd.Series(dtype='object')
                
                # ë°ì´í„° ë”•ì…”ë„ˆë¦¬ ìƒì„±
                data_dict = {}
                if date in new_data.index:
                    for col_name, value in row.items():
                        if not pd.isna(value):  # nullì´ ì•„ë‹Œ ê°’ë§Œ í¬í•¨
                            data_dict[col_name] = value
                
                # ì´ì „ ë°ì´í„°ë¡œ null ê°’ ì±„ìš°ê¸° (ëª¨ë“  ì»¬ëŸ¼ ëŒ€ìƒ)
                for col_name, value in previous_data.items():
                    if col_name != "ë‚ ì§œ" and col_name not in data_dict and value is not None:
                        data_dict[col_name] = value
                
                # ë°ì´í„° ë”•ì…”ë„ˆë¦¬ ê²€ì¦
                if not data_dict:
                    print(f"âš ï¸ {date_str}: ì €ì¥í•  ë°ì´í„°ê°€ ì—†ì–´ì„œ ê±´ë„ˆëœë‹ˆë‹¤.")
                    continue
                
                print(f"\nğŸ“Š {date_str} ë°ì´í„° ì¤€ë¹„ ì™„ë£Œ:")
                print(f"  - ì´ ì»¬ëŸ¼ ìˆ˜: {len(data_dict)}")
                print(f"  - ìƒ˜í”Œ ì»¬ëŸ¼: {list(data_dict.keys())[:5]}")
                
                # ì¬ì‹œë„ ë¡œì§ì´ í¬í•¨ëœ ì €ì¥ í•¨ìˆ˜ í˜¸ì¶œ
                if save_data_with_retry(date_str, data_dict):
                    # í˜„ì¬ ë°ì´í„°ë¥¼ ë‹¤ìŒ ë‚ ì§œ ì²˜ë¦¬ë¥¼ ìœ„í•œ ì´ì „ ë°ì´í„°ë¡œ ì„¤ì •
                    if data_dict:  # ë°ì´í„°ê°€ ìˆëŠ” ê²½ìš°ì—ë§Œ
                        previous_data = {"ë‚ ì§œ": date_str}
                        previous_data.update(data_dict)
                    
                    # ì£¼ìš” ì£¼ê°€ ë°ì´í„° ì¶œë ¥
                    for stock in stock_columns[:5]:
                        if stock in data_dict:
                            print(f"  ì €ì¥ ì „ {stock}: {data_dict[stock]}")
                    
                    saved_count += 1
                
            except Exception as e:
                # ê°œë³„ ë‚ ì§œ ì²˜ë¦¬ ì¤‘ ì—ëŸ¬ê°€ ë°œìƒí•´ë„ ê³„ì† ì§„í–‰
                print(f"{date_str} ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ (ë‹¤ìŒ ë‚ ì§œë¡œ ê³„ì† ì§„í–‰): {str(e)}")
                continue
        
        # ì˜¤ëŠ˜ ë‚ ì§œ ë°ì´í„°ëŠ” ìˆ˜ì§‘í–ˆì§€ë§Œ ì €ì¥í•˜ì§€ ì•ŠëŠ”ë‹¤ê³  í‘œì‹œ
        if datetime.now().date() in new_data.index:
            print(f"\n== {today} ë°ì´í„°ëŠ” ìˆ˜ì§‘í–ˆì§€ë§Œ ì €ì¥í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤ ==")
            
        total_records = len(all_dates)
        print(f"ì´ {total_records}ê°œ ë‚ ì§œ ì¤‘ {saved_count}ê°œê°€ ì²˜ë¦¬ë˜ì—ˆìŠµë‹ˆë‹¤.")
        
        # ===== ì¶”ê°€: ë°ì´í„° ì—…ë°ì´íŠ¸ ì™„ë£Œ í›„ ê¸°ìˆ ì  ì§€í‘œ ìƒì„± ë° ë‰´ìŠ¤ ê°ì • ë¶„ì„ ì‹¤í–‰ =====
        # try:
        #     print("ê¸°ìˆ ì  ì§€í‘œ ìƒì„± ì‹œì‘...")
        #     stock_service = StockRecommendationService()
        #     tech_result = stock_service.generate_technical_recommendations()
        #     print(f"ê¸°ìˆ ì  ì§€í‘œ ìƒì„± ì™„ë£Œ: {tech_result['message']}")
            
        #     print("ë‰´ìŠ¤ ê°ì • ë¶„ì„ ì‹œì‘...")
        #     sentiment_result = stock_service.fetch_and_store_sentiment_for_recommendations()
        #     print(f"ë‰´ìŠ¤ ê°ì • ë¶„ì„ ì™„ë£Œ: {sentiment_result['message']}")
        # except Exception as sub_e:
        #     # ì¶”ê°€ ì‘ì—… ì‹¤íŒ¨ ì‹œì—ë„ ì›ë˜ ì‘ì—…ì€ ì„±ê³µìœ¼ë¡œ ê°„ì£¼
        #     print(f"ì¶”ê°€ ë¶„ì„ ì‘ì—… ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(sub_e)}")
        #     import traceback
        #     print(traceback.format_exc())
        
        return {
            "success": True,
            "message": "ê²½ì œ ë°ì´í„° ì—…ë°ì´íŠ¸ ì™„ë£Œ",
            "total_records": total_records,
            "updated_records": saved_count
        }
    except Exception as e:
        print(f"ê²½ì œ ë°ì´í„° ì—…ë°ì´íŠ¸ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        import traceback
        print(traceback.format_exc())
        # ì—ëŸ¬ê°€ ë°œìƒí•´ë„ ì•±ì´ ê³„ì† ì‹¤í–‰ë˜ë„ë¡ ì˜ˆì™¸ë¥¼ ë‹¤ì‹œ ë°œìƒì‹œí‚¤ì§€ ì•Šê³  ë¡œê·¸ë§Œ ë‚¨ê¹€
        # í•„ìš”ì‹œ ì—ëŸ¬ ì •ë³´ë¥¼ ë°˜í™˜
        return {
            "success": False,
            "message": f"ê²½ì œ ë°ì´í„° ì—…ë°ì´íŠ¸ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}",
            "total_records": 0,
            "updated_records": 0
        }

print(f"Supabase URL: {settings.SUPABASE_URL}")