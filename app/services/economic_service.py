import pandas as pd
# stock.pyê°€ scripts/utils/ë¡œ ì´ë™í–ˆìœ¼ë¯€ë¡œ ê²½ë¡œ ìˆ˜ì •
from scripts.utils.stock import collect_economic_data
import numpy as np
from datetime import datetime, timedelta
import pytz
from app.core.config import settings
from fastapi import APIRouter, BackgroundTasks, HTTPException, Depends
from app.services.stock_recommendation_service import StockRecommendationService
from app.services.stock_service import get_stock_to_ticker_mapping, get_ticker_to_stock_mapping
from app.utils.slack_notifier import slack_notifier
import httpx
import time
import os
from app.db.mongodb import get_db
import logging

logger = logging.getLogger(__name__)


# ============================================================
# ë¹„ì¦ˆë‹ˆìŠ¤ ë¡œì§ í•¨ìˆ˜
# ============================================================

def fetch_economic_data(start_date: str = None, end_date: str = None):
    """
    ê²½ì œ ë°ì´í„°ë¥¼ ì¡°íšŒí•˜ê³  ë°˜í™˜í•©ë‹ˆë‹¤.
    
    Args:
        start_date: ìˆ˜ì§‘ ì‹œì‘ ë‚ ì§œ (YYYY-MM-DD í˜•ì‹, Noneì´ë©´ ìë™ ê³„ì‚°)
        end_date: ìˆ˜ì§‘ ì¢…ë£Œ ë‚ ì§œ (YYYY-MM-DD í˜•ì‹, Noneì´ë©´ ì˜¤ëŠ˜)
    
    Returns:
        dict: {
            'new_data': DataFrame,  # ìˆ˜ì§‘ëœ ë°ì´í„°
            'start_date': str,      # ìˆ˜ì§‘ ì‹œì‘ ë‚ ì§œ
            'storage_end_date': str,  # ì €ì¥ ì¢…ë£Œ ë‚ ì§œ
            'stock_columns': list,   # í™œì„±í™”ëœ ì£¼ì‹ ì»¬ëŸ¼
            'previous_data': dict,   # ì´ì „ ë°ì´í„°
            'today': str,           # ì˜¤ëŠ˜ ë‚ ì§œ
            'should_skip': bool     # ìˆ˜ì§‘ì„ ê±´ë„ˆë›¸ì§€ ì—¬ë¶€
        }
    """
    # ë¯¸êµ­ ì¥ ë§ˆê° ì—¬ë¶€ í™•ì¸ (ë‰´ìš• ì‹œê°„ ê¸°ì¤€ìœ¼ë¡œ ì •í™•íˆ ì²´í¬)
    now_korea = datetime.now(pytz.timezone('Asia/Seoul'))
    now_ny = datetime.now(pytz.timezone('America/New_York'))
    
    korea_time = now_korea.strftime('%H:%M')
    ny_hour = now_ny.hour
    ny_minute = now_ny.minute
    ny_weekday = now_ny.weekday()  # 0=ì›”ìš”ì¼, 6=ì¼ìš”ì¼
    
    # ë¯¸êµ­ ì£¼ì‹ ì‹œì¥ì€ í‰ì¼(ì›”-ê¸ˆ) 9:30 AM - 4:00 PM ET
    is_weekday = 0 <= ny_weekday <= 4  # ì›”ìš”ì¼ì—ì„œ ê¸ˆìš”ì¼ê¹Œì§€
    is_market_open_time = (
        (ny_hour == 9 and ny_minute >= 30) or
        (10 <= ny_hour < 16) or
        (ny_hour == 16 and ny_minute == 0)
    )
    
    is_market_hours = is_weekday and is_market_open_time
    
    # ë¯¸êµ­ ì£¼ì‹ ì‹œì¥ì´ ì—´ë ¤ ìˆëŠ” ê²½ìš°ì—ë§Œ ë°ì´í„° ìˆ˜ì§‘ ì—°ê¸°
    if is_market_hours:
        print(f"í˜„ì¬ ì‹œê°„ (í•œêµ­: {korea_time}, ë‰´ìš•: {now_ny.strftime('%Y-%m-%d %H:%M')})ì€ ë¯¸êµ­ ì£¼ì‹ ì‹œì¥ ìš´ì˜ ì‹œê°„ì…ë‹ˆë‹¤.")
        print(f"ì¥ ë§ˆê° í›„(ë‰´ìš• ì‹œê°„ 16:00 ì´í›„)ì— ë°ì´í„°ë¥¼ ìˆ˜ì§‘í•©ë‹ˆë‹¤.")
        return {'should_skip': True}
    
    print(f"í˜„ì¬ ì‹œê°„ (í•œêµ­: {korea_time}, ë‰´ìš•: {now_ny.strftime('%Y-%m-%d %H:%M')}) - ë¯¸êµ­ ì¥ ë§ˆê° ì‹œê°„ì´ë¯€ë¡œ ë°ì´í„° ìˆ˜ì§‘ì„ ì§„í–‰í•©ë‹ˆë‹¤.")

    # í•œêµ­ ì‹œê°„ëŒ€ ê¸°ì¤€ìœ¼ë¡œ í˜„ì¬ ë‚ ì§œ ê³„ì‚° (ì»¨í…Œì´ë„ˆ ì‹œê°„ëŒ€ ë¬¸ì œ ë°©ì§€)
    korea_tz = pytz.timezone('Asia/Seoul')
    now_korea_dt = datetime.now(korea_tz)
    today = now_korea_dt.strftime('%Y-%m-%d')
    yesterday = (now_korea_dt - timedelta(days=1)).strftime('%Y-%m-%d')
    
    # ë‚ ì§œ ë²”ìœ„ê°€ ì§€ì •ëœ ê²½ìš° ì‚¬ìš©, ì•„ë‹ˆë©´ ìë™ ê³„ì‚°
    if start_date and end_date:
        # ì‚¬ìš©ìê°€ ì§€ì •í•œ ë‚ ì§œ ë²”ìœ„ ì‚¬ìš©
        print(f"ì§€ì •ëœ ë‚ ì§œ ë²”ìœ„ë¡œ ìˆ˜ì§‘: {start_date} ~ {end_date}")
        collection_start_date = start_date
        collection_end_date = end_date
        storage_end_date = end_date  # ì§€ì •ëœ ë²”ìœ„ëŠ” ëª¨ë‘ ì €ì¥
    else:
        # ê¸°ë³¸ ë™ì‘: ë§ˆì§€ë§‰ ìˆ˜ì§‘ ë‚ ì§œ ì¡°íšŒ (ë‹¤ìŒ ìˆ˜ì§‘ ì‹œì‘ì¼ì„ ë°˜í™˜)
        next_collection_date = get_last_updated_date()
        
        # ì˜¤ëŠ˜ê¹Œì§€ ìˆ˜ì§‘í•´ì•¼ í•˜ë¯€ë¡œ, ìˆ˜ì§‘ ì‹œì‘ì¼ì„ ì¡°ì •
        # next_collection_dateê°€ ì˜¤ëŠ˜ë³´ë‹¤ í¬ê±°ë‚˜ ê°™ìœ¼ë©´, ì˜¤ëŠ˜ë¶€í„° ìˆ˜ì§‘
        if next_collection_date >= today:
            collection_start_date = today
            print(f"ë‹¤ìŒ ìˆ˜ì§‘ ì‹œì‘ì¼({next_collection_date})ì´ ì˜¤ëŠ˜({today})ë³´ë‹¤ í¬ê±°ë‚˜ ê°™ìœ¼ë¯€ë¡œ, ì˜¤ëŠ˜ ë°ì´í„°ë¶€í„° ìˆ˜ì§‘í•©ë‹ˆë‹¤.")
        else:
            collection_start_date = next_collection_date
        
        collection_end_date = today
        # ì˜¤ëŠ˜ ë°ì´í„°ë„ ì €ì¥ (API í˜¸ì¶œ ì‹œ ì˜¤ëŠ˜ ë°ì´í„° ìˆ˜ì§‘ ë° ì €ì¥)
        storage_end_date = today
    
    start_date = collection_start_date
    print(f"í•œêµ­ ì‹œê°„ ê¸°ì¤€ ì˜¤ëŠ˜: {today}, ì–´ì œ: {yesterday}, ìˆ˜ì§‘ ì‹œì‘ì¼: {start_date}, ìˆ˜ì§‘ ì¢…ë£Œì¼: {collection_end_date}")
    
    # ìˆ˜ì§‘ ì‹œì‘ì¼ì´ ì¢…ë£Œì¼ë³´ë‹¤ í¬ë©´ ìˆ˜ì§‘í•  ë°ì´í„°ê°€ ì—†ìŒ
    if start_date > collection_end_date:
        print(f"ìˆ˜ì§‘ ì‹œì‘ì¼({start_date})ì´ ì¢…ë£Œì¼({collection_end_date})ë³´ë‹¤ í½ë‹ˆë‹¤. ìˆ˜ì§‘í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return {'should_skip': True}
    
    # ì´ì „ ë°ì´í„° ê°€ì ¸ì˜¤ê¸° (ë§ˆì§€ë§‰ ìˆ˜ì§‘ ë‚ ì§œì˜ ë°ì´í„°) - MongoDBì—ì„œ ì¡°íšŒ
    previous_date = (datetime.strptime(start_date, '%Y-%m-%d') - timedelta(days=1)).strftime('%Y-%m-%d')
    previous_data = {}
    try:
        db = get_db()
        if db is not None:
            prev_doc = db.daily_stock_data.find_one({"date": previous_date})
            if prev_doc:
                # MongoDB ë¬¸ì„œë¥¼ API ì‘ë‹µ í˜•ì‹ìœ¼ë¡œ ë³€í™˜
                previous_data = {"ë‚ ì§œ": prev_doc.get("date")}
                # FRED ì§€í‘œ
                for key, value in prev_doc.get("fred_indicators", {}).items():
                    previous_data[key] = value
                # Yahoo Finance ì§€í‘œ
                for key, value in prev_doc.get("yfinance_indicators", {}).items():
                    previous_data[key] = value
                # ì£¼ê°€ ë°ì´í„° (í‹°ì»¤ë¥¼ ê·¸ëŒ€ë¡œ ì‚¬ìš© - categorize_data_for_mongodbì—ì„œ í‹°ì»¤ë„ ì¸ì‹í•¨)
                stocks_count = 0
                for ticker, stock_data in prev_doc.get("stocks", {}).items():
                    if isinstance(stock_data, dict):
                        previous_data[ticker] = stock_data.get("close_price")
                    else:
                        previous_data[ticker] = stock_data
                    stocks_count += 1
                
                if stocks_count > 0:
                    logger.debug(f"ì´ì „ ë°ì´í„°({previous_date})ì—ì„œ ì£¼ì‹ {stocks_count}ê°œ ë¡œë“œ ì™„ë£Œ")
                else:
                    logger.warning(f"ì´ì „ ë°ì´í„°({previous_date})ì— stocks í•„ë“œê°€ ì—†ê±°ë‚˜ ë¹„ì–´ìˆìŒ")
    except Exception as e:
        logger.warning(f"ì´ì „ ë°ì´í„° ì¡°íšŒ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
    
    # stock_columnsë¥¼ ìµœì‹  ìƒíƒœë¡œ ì—…ë°ì´íŠ¸ (ë§¤ë²ˆ ì‹¤í–‰ ì‹œ ìµœì‹  í™œì„±í™” ìƒíƒœ ë°˜ì˜)
    stock_columns = get_active_stock_columns()
    
    # ë°ì´í„° ìˆ˜ì§‘ (ì˜¤ëŠ˜ê¹Œì§€ ìˆ˜ì§‘)
    result = collect_economic_data(start_date=start_date, end_date=collection_end_date)
    
    # ë°˜í™˜ê°’ì´ íŠœí”Œì¸ ê²½ìš° (ê³µë§¤ë„ ë°ì´í„° í¬í•¨)ì™€ DataFrameë§Œ ë°˜í™˜í•˜ëŠ” ê²½ìš° ì²˜ë¦¬
    if isinstance(result, tuple):
        new_data, short_interest_data = result
    else:
        new_data = result
        short_interest_data = {}
    
    # ë””ë²„ê¹…: ìˆ˜ì§‘ëœ ë°ì´í„° í™•ì¸
    print("\n=== ìˆ˜ì§‘ëœ ë°ì´í„° í™•ì¸ ===")
    print(f"í™œì„±í™”ëœ ì£¼ì‹ ì»¬ëŸ¼ ìˆ˜: {len(stock_columns)}")
    if new_data is not None and not new_data.empty:
        for date_idx in new_data.index[:3]:  # ì²˜ìŒ 3ê°œ ë‚ ì§œë§Œ
            date_str = date_idx.strftime('%Y-%m-%d') if isinstance(date_idx, pd.Timestamp) else date_idx
            print(f"ë‚ ì§œ: {date_str}")
            for stock in stock_columns[:5]:  # ëª‡ ê°œì˜ ì£¼ê°€ë§Œ ì¶œë ¥
                if stock in new_data.columns:
                    print(f"  {stock}: {new_data.loc[date_idx, stock]}")
    
    if new_data is None or new_data.empty:
        print("ìˆ˜ì§‘í•  ìƒˆ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return {'should_skip': True}
    
    return {
        'should_skip': False,
        'new_data': new_data,
        'short_interest_data': short_interest_data,  # ê³µë§¤ë„ ë°ì´í„° ì¶”ê°€
        'start_date': start_date,
        'storage_end_date': storage_end_date,
        'stock_columns': stock_columns,
        'previous_data': previous_data,
        'today': today
    }


def categorize_data_for_mongodb(data_dict):
    """
    ë°ì´í„°ë¥¼ FRED, Yahoo Finance, Stocksë¡œ ë¶„ë¥˜í•©ë‹ˆë‹¤.
    
    Args:
        data_dict: ë¶„ë¥˜í•  ë°ì´í„° ë”•ì…”ë„ˆë¦¬
    
    Returns:
        dict: {
            'fred_indicators': {...},
            'yfinance_indicators': {...},
            'stocks': {...}
        }
    """
    try:
        db = get_db()
        if db is None:
            logger.warning("MongoDB ì—°ê²° ì‹¤íŒ¨ - ë°ì´í„° ë¶„ë¥˜ ë¶ˆê°€")
            return {'fred_indicators': {}, 'yfinance_indicators': {}, 'stocks': {}}
        
        # MongoDBì—ì„œ ê° ì¹´í…Œê³ ë¦¬ì˜ ì´ë¦„ ëª©ë¡ ê°€ì ¸ì˜¤ê¸°
        fred_names = set()
        yfinance_names = set()
        stock_names = set()
        
        # FRED ì§€í‘œ ì´ë¦„
        for doc in db.fred_indicators.find({"is_active": True}):
            if doc.get("name"):
                fred_names.add(doc["name"])
        
        # Yahoo Finance ì§€í‘œ ì´ë¦„
        for doc in db.yfinance_indicators.find({"is_active": True}):
            if doc.get("name"):
                yfinance_names.add(doc["name"])
        
        # ì£¼ì‹ ì´ë¦„ (í•œê¸€ ì£¼ì‹ëª…)
        for doc in db.stocks.find({"is_active": True}):
            if doc.get("stock_name"):
                stock_names.add(doc["stock_name"])
        
        # í‹°ì»¤ -> í•œê¸€ ì£¼ì‹ëª… ë§¤í•‘ ìƒì„± (í‹°ì»¤ë„ stocksë¡œ ë¶„ë¥˜í•˜ê¸° ìœ„í•´)
        ticker_to_stock = get_ticker_to_stock_mapping(exclude_etf=False)
        # í‹°ì»¤ ëª©ë¡ ìƒì„±
        tickers = set(ticker_to_stock.keys())
        
        # ë°ì´í„° ë¶„ë¥˜
        categorized = {
            'fred_indicators': {},
            'yfinance_indicators': {},
            'stocks': {}
        }
        
        # ë””ë²„ê¹…: ë¶„ë¥˜ë˜ì§€ ì•Šì€ ì£¼ì‹ ë°ì´í„° ì¶”ì 
        unclassified_stocks = []
        classified_stocks = []
        classified_by_ticker = []
        classified_by_stock_name = []
        
        for key, value in data_dict.items():
            if key in fred_names:
                categorized['fred_indicators'][key] = value
            elif key in yfinance_names:
                categorized['yfinance_indicators'][key] = value
            elif key in tickers:
                # í‹°ì»¤ì¸ ê²½ìš°ë¥¼ ë¨¼ì € í™•ì¸ (í‹°ì»¤ì™€ ì£¼ì‹ëª…ì´ ê²¹ì¹  ìˆ˜ ìˆìœ¼ë¯€ë¡œ)
                categorized['stocks'][key] = value
                classified_stocks.append(key)
                classified_by_ticker.append(key)
            elif key in stock_names:
                # í•œê¸€ ì£¼ì‹ëª…ì¸ ê²½ìš° (í‹°ì»¤ê°€ ì•„ë‹Œ ê²½ìš°ë§Œ)
                categorized['stocks'][key] = value
                classified_stocks.append(key)
                classified_by_stock_name.append(key)
            # ë¶„ë¥˜ë˜ì§€ ì•Šì€ ë°ì´í„°ëŠ” ë¬´ì‹œ (ë¡œê·¸ë§Œ ë‚¨ê¹€)
            else:
                # ì£¼ì‹ìœ¼ë¡œ ë³´ì´ëŠ” ë°ì´í„°ëŠ” ë³„ë„ë¡œ ì¶”ì 
                if key not in ['ë‚ ì§œ']:  # ë‚ ì§œëŠ” ì œì™¸
                    unclassified_stocks.append(key)
                logger.debug(f"ë¶„ë¥˜ë˜ì§€ ì•Šì€ ë°ì´í„°: {key}")
        
        # ë¶„ë¥˜ë˜ì§€ ì•Šì€ ë°ì´í„°ê°€ ìˆìœ¼ë©´ ê²½ê³  ë¡œê·¸ë§Œ ì¶œë ¥
        if unclassified_stocks:
            logger.warning(f"ë¶„ë¥˜ë˜ì§€ ì•Šì€ ì£¼ì‹ ë°ì´í„° {len(unclassified_stocks)}ê°œ ë°œê²¬: {unclassified_stocks[:10]}")
        
        logger.debug(f"ë°ì´í„° ë¶„ë¥˜ ì™„ë£Œ: FRED {len(categorized['fred_indicators'])}ê°œ, "
                    f"Yahoo Finance {len(categorized['yfinance_indicators'])}ê°œ, "
                    f"Stocks {len(categorized['stocks'])}ê°œ")
        
        return categorized
    except Exception as e:
        logger.error(f"ë°ì´í„° ë¶„ë¥˜ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        return {'fred_indicators': {}, 'yfinance_indicators': {}, 'stocks': {}}


def save_economic_data(new_data, start_date, storage_end_date, stock_columns, previous_data, today, short_interest_data=None):
    """
    ì¡°íšŒí•œ ê²½ì œ ë°ì´í„°ë¥¼ ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥í•©ë‹ˆë‹¤.
    
    Args:
        new_data: ìˆ˜ì§‘ëœ ë°ì´í„° DataFrame
        start_date: ìˆ˜ì§‘ ì‹œì‘ ë‚ ì§œ
        storage_end_date: ì €ì¥ ì¢…ë£Œ ë‚ ì§œ
        stock_columns: í™œì„±í™”ëœ ì£¼ì‹ ì»¬ëŸ¼ ë¦¬ìŠ¤íŠ¸
        previous_data: ì´ì „ ë°ì´í„° ë”•ì…”ë„ˆë¦¬
        today: ì˜¤ëŠ˜ ë‚ ì§œ
    
    Returns:
        dict: {'saved_count': int, 'total_records': int}
    """
    # ë‚ ì§œ ë²”ìœ„ ìƒì„± (ì‹œì‘ì¼ë¶€í„° ì–´ì œê¹Œì§€ë§Œ)
    all_dates = pd.date_range(start=start_date, end=storage_end_date)
    saved_count = 0
    
    # ì¬ì‹œë„ ë¡œì§ì´ í¬í•¨ëœ ë°ì´í„° ì €ì¥ í•¨ìˆ˜ (MongoDB ì „ìš©)
    def save_data_with_retry(date_str, data_dict, max_retries=3, short_interest_data_for_date=None):
        """MongoDBì— ë°ì´í„° ì €ì¥ì„ ì¬ì‹œë„í•˜ë©° ì²˜ë¦¬"""
        # ë°ì´í„° ë”•ì…”ë„ˆë¦¬ ê²€ì¦
        if not data_dict:
            print(f"âš ï¸ {date_str}: ì €ì¥í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤ (data_dictê°€ ë¹„ì–´ìˆìŒ)")
            return False
        
        # ë‚ ì§œëŠ” í•„ìˆ˜
        if not date_str:
            print(f"âš ï¸ ë‚ ì§œê°€ ì—†ì–´ì„œ ì €ì¥í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
            return False
        
        for attempt in range(max_retries):
            try:
                db = get_db()
                if db is None:
                    logger.error(f"MongoDB ì—°ê²° ì‹¤íŒ¨: {date_str}")
                    return False
                
                # ë°ì´í„° ë¶„ë¥˜
                categorized = categorize_data_for_mongodb(data_dict)
                
                # ë¶„ë¥˜ ê²°ê³¼ ë¡œê¹… (ë””ë²„ê·¸ ë ˆë²¨)
                logger.debug(f"{date_str} ë°ì´í„° ë¶„ë¥˜: FRED {len(categorized['fred_indicators'])}ê°œ, "
                           f"Yahoo Finance {len(categorized['yfinance_indicators'])}ê°œ, "
                           f"Stocks {len(categorized['stocks'])}ê°œ")
                
                # stocks í•„ë“œì— ê³µë§¤ë„ ë°ì´í„° í†µí•©
                # í‹°ì»¤ <-> í•œê¸€ ì£¼ì‹ëª… ë§¤í•‘ ìƒì„±
                stock_to_ticker = get_stock_to_ticker_mapping(exclude_etf=False)
                ticker_to_stock = get_ticker_to_stock_mapping(exclude_etf=False)
                
                # stocks í•„ë“œë¥¼ í‹°ì»¤ ê¸°ë°˜ìœ¼ë¡œ ë³€í™˜ (None ê°’ í•„í„°ë§)
                stocks_with_short_interest = {}
                ticker_not_found_stocks = []
                none_price_count = 0
                
                for key, price in categorized['stocks'].items():
                    # None ê°’ì€ ì €ì¥í•˜ì§€ ì•ŠìŒ
                    if price is None:
                        none_price_count += 1
                        continue
                    
                    # keyê°€ í‹°ì»¤ì¸ì§€ í•œê¸€ ì£¼ì‹ëª…ì¸ì§€ í™•ì¸
                    if key in ticker_to_stock:
                        # ì´ë¯¸ í‹°ì»¤ì¸ ê²½ìš°
                        ticker = key
                    else:
                        # í•œê¸€ ì£¼ì‹ëª…ì¸ ê²½ìš° í‹°ì»¤ë¡œ ë³€í™˜
                        ticker = stock_to_ticker.get(key)
                    
                    if ticker:
                        # í‹°ì»¤ë¥¼ í‚¤ë¡œ ì‚¬ìš©
                        stocks_with_short_interest[ticker] = {
                            'close_price': price
                        }
                    else:
                        ticker_not_found_stocks.append(key)
                
                if none_price_count > 0:
                    logger.warning(f"{date_str}: None ê°’ ê°€ê²© {none_price_count}ê°œëŠ” ì €ì¥í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
                
                if ticker_not_found_stocks:
                    logger.warning(f"{date_str}: í‹°ì»¤ë¥¼ ì°¾ì„ ìˆ˜ ì—†ëŠ” ì£¼ì‹ëª… {len(ticker_not_found_stocks)}ê°œ: {ticker_not_found_stocks[:5]}")
                
                # ê³µë§¤ë„ ë°ì´í„° í†µí•© (í‹°ì»¤ ê¸°ë°˜)
                if short_interest_data_for_date:
                    logger.debug(f"{date_str}: ê³µë§¤ë„ ë°ì´í„° {len(short_interest_data_for_date)}ê°œ í‹°ì»¤ í†µí•©")
                    for ticker, stock_data in short_interest_data_for_date.items():
                        if ticker in stocks_with_short_interest:
                            # ê¸°ì¡´ close_price ê°€ê²©ê³¼ ê³µë§¤ë„ ë°ì´í„° í†µí•©
                            stocks_with_short_interest[ticker].update(stock_data)
                        else:
                            # ê°€ê²© ë°ì´í„°ê°€ ì—†ì–´ë„ ê³µë§¤ë„ ë°ì´í„°ë§Œ ì €ì¥
                            stocks_with_short_interest[ticker] = stock_data
                
                logger.debug(f"{date_str}: ìµœì¢… ì €ì¥ë  Stocks ìˆ˜: {len(stocks_with_short_interest)}ê°œ")
                
                # MongoDBì— upsert (êµ¬ì¡°í™”ëœ í˜•íƒœë¡œ)
                mongo_doc = {
                    "date": date_str,
                    "fred_indicators": categorized['fred_indicators'],
                    "yfinance_indicators": categorized['yfinance_indicators'],
                    "stocks": stocks_with_short_interest,
                    "updated_at": datetime.utcnow()
                }
                
                db.daily_stock_data.update_one(
                    {"date": date_str},
                    {
                        "$set": mongo_doc,
                        "$setOnInsert": {
                            "created_at": datetime.utcnow()
                        }
                    },
                    upsert=True
                )
                print(f"  âœ… MongoDB ì €ì¥ ì„±ê³µ: {date_str}")
                return True  # ì„±ê³µ
                
            except Exception as e:
                if attempt < max_retries - 1:
                    print(f"  âš ï¸ {date_str} ì €ì¥ ì‹¤íŒ¨ (ì‹œë„ {attempt+1}/{max_retries}): {str(e)}. ì¬ì‹œë„...")
                    time.sleep(2)  # ì¬ì‹œë„ ì „ ëŒ€ê¸°
                else:
                    print(f"  âŒ {date_str} ì €ì¥ ìµœì¢… ì‹¤íŒ¨: {str(e)}")
                    import traceback
                    print(traceback.format_exc())
                    return False
        return False
    
    # ì–´ì œê¹Œì§€ ë‚ ì§œì— ëŒ€í•´ì„œë§Œ ì²˜ë¦¬
    for date in all_dates:
        try:
            date_str = date.strftime('%Y-%m-%d')
            
            # í•´ë‹¹ ë‚ ì§œì˜ ë°ì´í„°ê°€ ìˆ˜ì§‘ë˜ì—ˆëŠ”ì§€ í™•ì¸
            if date in new_data.index:
                row = new_data.loc[date]
                print(f"\n== {date_str} ë°ì´í„°ê°€ ìˆìŒ (ì €ì¥ ëŒ€ìƒ) ==")
                # ì£¼ìš” ì£¼ê°€ ë°ì´í„° ëª‡ ê°œ ì¶œë ¥
                for stock in stock_columns[:5]:
                    if stock in row.index:
                        print(f"  ì›ë³¸ {stock}: {row[stock]}")
            else:
                print(f"\n== {date_str} ë°ì´í„°ê°€ ì—†ìŒ, ì´ì „ ë°ì´í„° ì‚¬ìš© (ì €ì¥ ëŒ€ìƒ) ==")
                row = pd.Series(dtype='object')
            
            # ë°ì´í„° ë”•ì…”ë„ˆë¦¬ ìƒì„±
            data_dict = {}
            if date in new_data.index:
                for col_name, value in row.items():
                    if not pd.isna(value):  # nullì´ ì•„ë‹Œ ê°’ë§Œ í¬í•¨
                        data_dict[col_name] = value
            
            # ì´ì „ ë°ì´í„°ë¡œ null ê°’ ì±„ìš°ê¸° (ëª¨ë“  ì»¬ëŸ¼ ëŒ€ìƒ)
            for col_name, value in previous_data.items():
                if col_name != "ë‚ ì§œ" and col_name not in data_dict and value is not None:
                    data_dict[col_name] = value
            
            # ì¤‘ìš”: ì´ì „ ë°ì´í„°ì— ì£¼ì‹ì´ ì—†ê±°ë‚˜ ì ì€ ê²½ìš°, ë” ì´ì „ ë‚ ì§œì˜ ë°ì´í„°ì—ì„œ ê°€ê²©ì„ ì°¾ì•„ì„œ ì¶”ê°€
            from app.services.stock_service import get_active_tickers
            active_tickers = get_active_tickers(exclude_etf=False)
            ticker_to_stock = get_ticker_to_stock_mapping(exclude_etf=False)
            
            # data_dictì— ì—†ëŠ” í‹°ì»¤ë“¤ì„ í™•ì¸í•˜ê³  ì´ì „ ë‚ ì§œ ë°ì´í„°ì—ì„œ ê°€ê²© ì°¾ê¸°
            missing_tickers = [ticker for ticker in active_tickers if ticker not in data_dict]
            if missing_tickers:
                logger.debug(f"{date_str}: í™œì„±í™”ëœ ì£¼ì‹ ì¤‘ data_dictì— ì—†ëŠ” í‹°ì»¤ {len(missing_tickers)}ê°œ ë°œê²¬")
                
                # ë” ì´ì „ ë‚ ì§œì˜ ë°ì´í„°ì—ì„œ ê°€ê²© ì°¾ê¸° (ìµœëŒ€ 30ì¼ ì „ê¹Œì§€)
                db = get_db()
                if db:
                    found_count = 0
                    for days_back in range(1, 31):  # 1ì¼ ì „ë¶€í„° 30ì¼ ì „ê¹Œì§€
                        search_date = (datetime.strptime(date_str, '%Y-%m-%d') - timedelta(days=days_back)).strftime('%Y-%m-%d')
                        prev_doc = db.daily_stock_data.find_one({"date": search_date})
                        
                        if prev_doc:
                            prev_stocks = prev_doc.get("stocks", {})
                            for ticker in missing_tickers[:]:  # ë³µì‚¬ë³¸ìœ¼ë¡œ ìˆœíšŒ
                                if ticker in prev_stocks:
                                    stock_data = prev_stocks[ticker]
                                    if isinstance(stock_data, dict):
                                        price = stock_data.get("close_price")
                                    else:
                                        price = stock_data
                                    
                                    if price is not None:
                                        data_dict[ticker] = price
                                        missing_tickers.remove(ticker)
                                        found_count += 1
                                        if found_count >= len(missing_tickers):
                                            break
                        
                        if not missing_tickers:  # ëª¨ë‘ ì°¾ì•˜ìœ¼ë©´ ì¤‘ë‹¨
                            break
                    
                    if found_count > 0:
                        logger.debug(f"{date_str}: {found_count}ê°œ í‹°ì»¤ì˜ ê°€ê²©ì„ ì´ì „ ë‚ ì§œ ë°ì´í„°ì—ì„œ ì°¾ì•„ì„œ ì¶”ê°€í–ˆìŠµë‹ˆë‹¤.")
                    if missing_tickers:
                        logger.warning(f"{date_str}: {len(missing_tickers)}ê°œ í‹°ì»¤ëŠ” ê°€ê²©ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤: {missing_tickers[:10]}")
            
            # ë°ì´í„° ë”•ì…”ë„ˆë¦¬ ê²€ì¦
            if not data_dict:
                print(f"âš ï¸ {date_str}: ì €ì¥í•  ë°ì´í„°ê°€ ì—†ì–´ì„œ ê±´ë„ˆëœë‹ˆë‹¤.")
                continue
            
            print(f"\nğŸ“Š {date_str} ë°ì´í„° ì¤€ë¹„ ì™„ë£Œ:")
            
            # ì¬ì‹œë„ ë¡œì§ì´ í¬í•¨ëœ ì €ì¥ í•¨ìˆ˜ í˜¸ì¶œ
            date_short_interest = short_interest_data.get(date_str, {}) if short_interest_data else {}
            if save_data_with_retry(date_str, data_dict, short_interest_data_for_date=date_short_interest):
                # í˜„ì¬ ë°ì´í„°ë¥¼ ë‹¤ìŒ ë‚ ì§œ ì²˜ë¦¬ë¥¼ ìœ„í•œ ì´ì „ ë°ì´í„°ë¡œ ì„¤ì •
                if data_dict:  # ë°ì´í„°ê°€ ìˆëŠ” ê²½ìš°ì—ë§Œ
                    previous_data = {"ë‚ ì§œ": date_str}
                    previous_data.update(data_dict)
                
                # ì£¼ìš” ì£¼ê°€ ë°ì´í„° ì¶œë ¥
                for stock in stock_columns[:5]:
                    if stock in data_dict:
                        print(f"  ì €ì¥ ì „ {stock}: {data_dict[stock]}")
                
                saved_count += 1
            
        except Exception as e:
            # ê°œë³„ ë‚ ì§œ ì²˜ë¦¬ ì¤‘ ì—ëŸ¬ê°€ ë°œìƒí•´ë„ ê³„ì† ì§„í–‰
            print(f"{date_str} ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ (ë‹¤ìŒ ë‚ ì§œë¡œ ê³„ì† ì§„í–‰): {str(e)}")
            continue
    
    # ì˜¤ëŠ˜ ë‚ ì§œ ë°ì´í„°ëŠ” ìˆ˜ì§‘í–ˆì§€ë§Œ ì €ì¥í•˜ì§€ ì•ŠëŠ”ë‹¤ê³  í‘œì‹œ
    if datetime.now().date() in new_data.index:
        print(f"\n== {today} ë°ì´í„°ëŠ” ìˆ˜ì§‘í–ˆì§€ë§Œ ì €ì¥í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤ ==")
    
    total_records = len(all_dates)
    print(f"ì´ {total_records}ê°œ ë‚ ì§œ ì¤‘ {saved_count}ê°œê°€ ì²˜ë¦¬ë˜ì—ˆìŠµë‹ˆë‹¤.")
    
    return {
        'saved_count': saved_count,
        'total_records': total_records
    }


async def update_economic_data_in_background(start_date: str = None, end_date: str = None):
    """
    ë°±ê·¸ë¼ìš´ë“œì—ì„œ ê²½ì œ ì§€í‘œ ë°ì´í„°ë¥¼ ì—…ë°ì´íŠ¸
    
    Args:
        start_date: ìˆ˜ì§‘ ì‹œì‘ ë‚ ì§œ (YYYY-MM-DD í˜•ì‹, Noneì´ë©´ ìë™ ê³„ì‚°)
        end_date: ìˆ˜ì§‘ ì¢…ë£Œ ë‚ ì§œ (YYYY-MM-DD í˜•ì‹, Noneì´ë©´ ì˜¤ëŠ˜)
    """
    try:
        print("ê²½ì œ ì§€í‘œ ë° ì£¼ê°€ ë°ì´í„° ì—…ë°ì´íŠ¸ ì‘ì—… ì‹œì‘...")
        
        # 1. ë°ì´í„° ì¡°íšŒ
        fetch_result = fetch_economic_data(start_date=start_date, end_date=end_date)
        
        # ì¡°íšŒë¥¼ ê±´ë„ˆë›°ì–´ì•¼ í•˜ëŠ” ê²½ìš° (ì‹œì¥ ìš´ì˜ ì‹œê°„, ë°ì´í„° ì—†ìŒ ë“±)
        if fetch_result.get('should_skip'):
            return {"success": True, "total_records": 0, "updated_records": 0}
        
        # 2. ë°ì´í„° ì €ì¥
        save_result = save_economic_data(
            new_data=fetch_result['new_data'],
            start_date=fetch_result['start_date'],
            storage_end_date=fetch_result['storage_end_date'],
            stock_columns=fetch_result['stock_columns'],
            previous_data=fetch_result['previous_data'],
            today=fetch_result['today'],
            short_interest_data=fetch_result.get('short_interest_data', {})
        )
        
        # 3. ê³µë§¤ë„ ì •ë³´ ìŠ¬ë™ ì „ì†¡
        short_interest_data = fetch_result.get('short_interest_data', {})
        if short_interest_data:
            try:
                # í‹°ì»¤ -> ì£¼ì‹ëª… ë§¤í•‘ ìƒì„±
                ticker_to_stock_mapping = get_ticker_to_stock_mapping(exclude_etf=False)
                # ê³µë§¤ë„ ì •ë³´ ìŠ¬ë™ ì „ì†¡
                slack_notifier.send_short_interest_notification(
                    short_interest_data=short_interest_data,
                    ticker_to_stock_mapping=ticker_to_stock_mapping
                )
            except Exception as slack_e:
                logger.warning(f"ê³µë§¤ë„ ì •ë³´ ìŠ¬ë™ ì „ì†¡ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(slack_e)}")
        
        # ì°¸ê³ : ê¸°ìˆ ì  ì§€í‘œ ìƒì„± ë° ë‰´ìŠ¤ ê°ì • ë¶„ì„ì€ ë³„ë„ APIë¡œ ë¶„ë¦¬ë¨
        # - ê¸°ìˆ ì  ì§€í‘œ: POST /recommended-stocks/generate-technical-recommendations
        # - ê°ì • ë¶„ì„: POST /recommended-stocks/analyze-news-sentiment
        # - í†µí•© ë¶„ì„: POST /recommended-stocks/generate-complete-analysis
        
        return {
            "success": True,
            "message": "ê²½ì œ ë° ì£¼ì‹ ë°ì´í„° ì—…ë°ì´íŠ¸ ì™„ë£Œ",
            "total_records": save_result['total_records'],
            "updated_records": save_result['saved_count']
        }
    except Exception as e:
        print(f"ê²½ì œ ë°ì´í„° ì—…ë°ì´íŠ¸ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        import traceback
        print(traceback.format_exc())
        # ì—ëŸ¬ê°€ ë°œìƒí•´ë„ ì•±ì´ ê³„ì† ì‹¤í–‰ë˜ë„ë¡ ì˜ˆì™¸ë¥¼ ë‹¤ì‹œ ë°œìƒì‹œí‚¤ì§€ ì•Šê³  ë¡œê·¸ë§Œ ë‚¨ê¹€
        return {
            "success": False,
            "message": f"ê²½ì œ ë°ì´í„° ì—…ë°ì´íŠ¸ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}",
            "total_records": 0,
            "updated_records": 0
        }


# ============================================================
# ë°ì´í„° ì¡°íšŒ ë° í—¬í¼ í•¨ìˆ˜
# ============================================================

def get_last_updated_date():
    """
    MongoDBì˜ daily_stock_data ì»¬ë ‰ì…˜ì—ì„œ ë§ˆì§€ë§‰ìœ¼ë¡œ ìˆ˜ì§‘ëœ ë‚ ì§œë¥¼ ì¡°íšŒí•©ë‹ˆë‹¤.
    """
    try:
        # MongoDBì—ì„œ ì¡°íšŒ
        db = get_db()
        if db is None:
            logger.error("MongoDB ì—°ê²° ì‹¤íŒ¨. ê¸°ë³¸ ì‹œì‘ ë‚ ì§œë¡œ ì„¤ì •í•©ë‹ˆë‹¤.")
            return "2006-01-01"
        
        # daily_stock_data ì»¬ë ‰ì…˜ì—ì„œ ë§ˆì§€ë§‰ ë‚ ì§œ ì¡°íšŒ
        last_doc = db.daily_stock_data.find_one(
            sort=[("date", -1)]
        )
        
        if last_doc and "date" in last_doc:
            date = last_doc["date"]
            
            # dateê°€ ë¬¸ìì—´ì¸ ê²½ìš° datetimeìœ¼ë¡œ ë³€í™˜
            if isinstance(date, str):
                last_date = datetime.fromisoformat(date.replace('Z', '+00:00'))
            elif isinstance(date, datetime):
                last_date = date
            else:
                # ë‹¤ë¥¸ íƒ€ì…ì¸ ê²½ìš° ë³€í™˜ ì‹œë„
                last_date = pd.to_datetime(date).to_pydatetime()
            
            # ë‹¤ìŒ ë‚ ì§œ ë°˜í™˜
            next_date = (last_date + timedelta(days=1)).strftime('%Y-%m-%d')
            print(f"ë§ˆì§€ë§‰ ìˆ˜ì§‘ ë‚ ì§œ (MongoDB daily_stock_data): {last_date.strftime('%Y-%m-%d')}, ë‹¤ìŒ ìˆ˜ì§‘ ì‹œì‘ì¼: {next_date}")
            return next_date
        else:
            # ë°ì´í„°ê°€ ì—†ìœ¼ë©´ ê¸°ë³¸ ì‹œì‘ ë‚ ì§œ ë°˜í™˜ (2006-01-01)
            print("MongoDB daily_stock_data ì»¬ë ‰ì…˜ì— ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. ê¸°ë³¸ ì‹œì‘ ë‚ ì§œ(2006-01-01)ë¡œ ì„¤ì •í•©ë‹ˆë‹¤.")
            return "2006-01-01"
            
    except Exception as e:
        print(f"ë§ˆì§€ë§‰ ìˆ˜ì§‘ ë‚ ì§œ ì¡°íšŒ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        import traceback
        print(traceback.format_exc())
        # ì˜¤ë¥˜ ë°œìƒ ì‹œ ê¸°ë³¸ ì‹œì‘ ë‚ ì§œ ë°˜í™˜
        return "2006-01-01"



def get_active_stock_columns():
    """
    MongoDBì˜ stocks, fred_indicators, yfinance_indicators ì»¬ë ‰ì…˜ì—ì„œ í™œì„±í™”ëœ ì£¼ì‹ ë° ì§€í‘œ ëª©ë¡ì„ ê°€ì ¸ì˜µë‹ˆë‹¤.
    """
    try:
        from app.core.config import settings
        
        # MongoDB ì‚¬ìš© ì—¬ë¶€ í™•ì¸ (config.pyë¥¼ í†µí•´ì„œë§Œ ì ‘ê·¼)
        use_mongodb = settings.is_mongodb_enabled()
        
        if not use_mongodb:
            print("âš ï¸ ê²½ê³ : USE_MONGODBê°€ Falseë¡œ ì„¤ì •ë˜ì–´ ìˆìŠµë‹ˆë‹¤. ê¸°ë³¸ ëª©ë¡ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.")
            return _get_default_stock_columns()
        
        db = get_db()
        if db is None:
            print("âš ï¸ ê²½ê³ : MongoDB ì—°ê²° ì‹¤íŒ¨ (get_db()ê°€ None ë°˜í™˜). ê¸°ë³¸ ëª©ë¡ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.")
            print("   - USE_MONGODB ì„¤ì •ì„ í™•ì¸í•˜ì„¸ìš”.")
            print("   - MongoDB ì—°ê²° ì •ë³´ë¥¼ í™•ì¸í•˜ì„¸ìš”.")
            return _get_default_stock_columns()
        
        # MongoDBì—ì„œ í™œì„±í™”ëœ ì£¼ì‹ ëª©ë¡ ê°€ì ¸ì˜¤ê¸° (stocks ì»¬ë ‰ì…˜)
        try:
            from app.services.stock_service import get_active_stock_names
            active_stock_names = get_active_stock_names(exclude_etf=False)
        except Exception as e:
            logger.warning(f"âš ï¸ ê²½ê³ : stocks ì»¬ë ‰ì…˜ ì¡°íšŒ ì‹¤íŒ¨: {str(e)}. ê¸°ë³¸ ëª©ë¡ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.")
            return _get_default_stock_columns()
        
        # MongoDBì—ì„œ í™œì„±í™”ëœ ì‹œì¥ ì§€í‘œ ë° ETF ëª©ë¡ ê°€ì ¸ì˜¤ê¸°
        # fred_indicatorsì™€ yfinance_indicators ì»¬ë ‰ì…˜ì—ì„œ ì¡°íšŒ
        try:
            economic_and_etf_columns = []
            # FRED ì§€í‘œ
            active_fred = db.fred_indicators.find({"is_active": True})
            for indicator in active_fred:
                economic_and_etf_columns.append(indicator.get("name"))
            # Yahoo Finance ì§€í‘œ
            active_yfinance = db.yfinance_indicators.find({"is_active": True})
            for indicator in active_yfinance:
                economic_and_etf_columns.append(indicator.get("name"))
        except Exception as e:
            print(f"âš ï¸ ê²½ê³ : ì§€í‘œ ì»¬ë ‰ì…˜ ì¡°íšŒ ì‹¤íŒ¨: {str(e)}. ê¸°ë³¸ ëª©ë¡ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.")
            return _get_default_stock_columns()
        
        # í™œì„±í™”ëœ ì£¼ì‹ + ê²½ì œ ì§€í‘œ/ETF í•©ì¹˜ê¸°
        all_stock_columns = economic_and_etf_columns + active_stock_names
        
        if len(all_stock_columns) == 0:
            print("âš ï¸ ê²½ê³ : í™œì„±í™”ëœ ì£¼ì‹ ë° ì§€í‘œê°€ ì—†ìŠµë‹ˆë‹¤. ê¸°ë³¸ ëª©ë¡ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.")
            return _get_default_stock_columns()
        
        return all_stock_columns
    except Exception as e:
        print(f"âš ï¸ ê²½ê³ : MongoDB ì¡°íšŒ ì‹¤íŒ¨: {str(e)}. ê¸°ë³¸ ëª©ë¡ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.")
        import traceback
        print(traceback.format_exc())
        return _get_default_stock_columns()


def _get_default_stock_columns():
    """
    ê¸°ë³¸ ì£¼ì‹ ì»¬ëŸ¼ ëª©ë¡ ë°˜í™˜ (fallback)
    âš ï¸ ê²½ê³ : ì´ í•¨ìˆ˜ëŠ” MongoDB ì¡°íšŒ ì‹¤íŒ¨ ì‹œì—ë§Œ ì‚¬ìš©ë©ë‹ˆë‹¤. 
    ì •ìƒ ë™ì‘ ì‹œì—ëŠ” get_active_stock_columns()ë¥¼ ì‚¬ìš©í•´ì•¼ í•©ë‹ˆë‹¤.
    """
    logger.warning("âš ï¸ ê²½ê³ : í•˜ë“œì½”ë”©ëœ ê¸°ë³¸ ì£¼ì‹ ì»¬ëŸ¼ ëª©ë¡ì„ ì‚¬ìš©í•©ë‹ˆë‹¤. MongoDB ì¡°íšŒë¥¼ í™•ì¸í•˜ì„¸ìš”.")
    return [
        "ë‚˜ìŠ¤ë‹¥ ì¢…í•©ì§€ìˆ˜", "S&P 500 ì§€ìˆ˜", "ê¸ˆ ê°€ê²©", "ë‹¬ëŸ¬ ì¸ë±ìŠ¤", "ë‚˜ìŠ¤ë‹¥ 100", 
        "S&P 500 ETF", "QQQ ETF", "ëŸ¬ì…€ 2000 ETF", "ë‹¤ìš° ì¡´ìŠ¤ ETF", "VIX ì§€ìˆ˜", 
        "ë‹›ì¼€ì´ 225", "ìƒí•´ì¢…í•©", "í•­ì…", "ì˜êµ­ FTSE", "ë…ì¼ DAX", "í”„ë‘ìŠ¤ CAC 40", 
        "ë¯¸êµ­ ì „ì²´ ì±„ê¶Œì‹œì¥ ETF", "TIPS ETF", "íˆ¬ìë“±ê¸‰ íšŒì‚¬ì±„ ETF", "ë‹¬ëŸ¬/ì—”", "ë‹¬ëŸ¬/ìœ„ì•ˆ",
        "ë¯¸êµ­ ë¦¬ì¸  ETF", "SOXX ETF", "ì• í”Œ", "ë§ˆì´í¬ë¡œì†Œí”„íŠ¸", "ì•„ë§ˆì¡´", "êµ¬ê¸€ A", "êµ¬ê¸€ C", "ë©”íƒ€", 
        "í…ŒìŠ¬ë¼", "ì—”ë¹„ë””ì•„", "ì¸í…”", "ë§ˆì´í¬ë¡ ", "ë¸Œë¡œë“œì»´", 
        "í…ì‚¬ìŠ¤ ì¸ìŠ¤íŠ¸ë£¨ë¨¼íŠ¸", "AMD", "ì–´í”Œë¼ì´ë“œ ë¨¸í‹°ë¦¬ì–¼ì¦ˆ",
        "ì…€ë ˆìŠ¤í‹°ì¹´", "ë²„í‹°ë¸Œ í™€ë”©ìŠ¤", "ë¹„ìŠ¤íŠ¸ë¼ ì—ë„ˆì§€", "ë¸”ë£¸ì—ë„ˆì§€", "ì˜¤í´ë¡œ", "íŒ”ë€í‹°ì–´",
        "ì„¸ì¼ì¦ˆí¬ìŠ¤", "ì˜¤ë¼í´", "ì•±í”Œë¡œë¹ˆ", "íŒ”ë¡œì•Œí†  ë„¤íŠ¸ì›ìŠ¤", "í¬ë¼ìš°ë“œ ìŠ¤íŠ¸ë¼ì´í¬",
        "ìŠ¤ë…¸ìš°í”Œë ˆì´í¬", "TSMC", "í¬ë¦¬ë„ í…Œí¬ë†€ë¡œì§€ ê·¸ë£¹ í™€ë”©", "ë¡œë¹ˆí›„ë“œ", "ì¼ë¼ì´ë¦´ë¦¬",
        "ì›”ë§ˆíŠ¸", "ì¡´ìŠ¨ì•¤ì¡´ìŠ¨"
    ]

